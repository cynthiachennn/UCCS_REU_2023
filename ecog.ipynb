{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now attempt loading ecog data.\n",
    "\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import re\n",
    "\n",
    "# some hyperparameter type things :)\n",
    "sr = 1000\n",
    "t = 1000\n",
    "affix = '_raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the raw data from .mat\n",
    "# do preprocessing if necessary (can tweak this part)\n",
    "\n",
    "fileList = []\n",
    "subjList = ['bp', 'cc', 'ht', 'jp', 'mv', 'wc', 'zt'] #  'jc' 'wm', <take out\n",
    "\n",
    "for subj in subjList:\n",
    "    data = scipy.io.loadmat(f'preprocessing/raw_data/{subj}_fingerflex.mat')['data'].T\n",
    "    ch = data.shape[0]\n",
    "    # print(data.shape)\n",
    "    events = scipy.io.loadmat(f'preprocessing/{subj}_labels.mat')['Labels'][:, 1:3]\n",
    "    events = np.insert(events, 1, np.zeros(len(events)), axis=1)\n",
    "    \n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    for event in events:\n",
    "        time = int(event[0])\n",
    "        # if sr == 1000: time = int(time/5)\n",
    "        type = int(event[2])\n",
    "        features.append([data[i][time:time+1000] for i in range(ch)])\n",
    "        labels.append(type - 1)\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # print(features.shape, labels.shape)\n",
    "    fileList.append((subj, np.array(features), np.array(labels)))\n",
    "\n",
    "\n",
    "for subj, file, labels in fileList:\n",
    "    np.save(f'pickles/{subj}_features{affix}', file)\n",
    "    np.save(f'pickles/{subj}_labels{affix}', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load .npy files\n",
    "fileList = []\n",
    "\n",
    "for subj in ['bp', 'cc', 'ht', 'jp', 'mv', 'wc', 'zt']:\n",
    "    features = np.load(f'pickles/{subj}_features{affix}.npy')\n",
    "    labels = np.load(f'pickles/{subj}_labels{affix}.npy')\n",
    "    fileList.append((subj, features, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2D CNN w/ Adham's recommendations\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class ConvNet_2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet_2D, self).__init__()\n",
    "        ### FILL IN ### [10 POINTS]\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, (7, 3)),\n",
    "            nn.ReLU(), \n",
    "            #nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(8, 16, (5, 3)),\n",
    "            nn.Conv2d(16, 32, (3, 3)),\n",
    "            nn.ReLU(),\n",
    "            #nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.hidden = nn.Sequential(\n",
    "            # nn.Flatten(),\n",
    "            # lol ok to calculate the size of the linear layer ...\n",
    "            # width = starting width (time) - combined (kernel sizes + 1) < constant = 1000 - 4 994\n",
    "            # height = starting height (channels) - combined (kernel heights + 1) < variable = ch - 12\n",
    "            # nn.Linear(() * 994 * 32, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4), # all features norefer\n",
    "            # nn.Linear(1408, 256), #pseudosampled featrues .\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128, 5),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### FILL IN ### [5 POINTS]\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x_flat = x.shape[1] * x.shape[2] * x.shape[3]\n",
    "        flat = nn.Flatten()\n",
    "        x = flat(x)\n",
    "        linear = nn.Linear(x_flat, 256)\n",
    "        # print(x.shape, x_flat)\n",
    "        x = linear(x)\n",
    "        x = self.hidden(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m targets \u001b[39m=\u001b[39m targets\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     22\u001b[0m \u001b[39m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m conv_net_predictions \u001b[39m=\u001b[39m conv_net(data)\n\u001b[1;32m     24\u001b[0m conv_net_loss \u001b[39m=\u001b[39m criterion(conv_net_predictions, targets)\n\u001b[1;32m     26\u001b[0m \u001b[39m# Backward pass\u001b[39;00m\n",
      "File \u001b[0;32m/net/home/store/home/cchen4/5F_EEG_DATA/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[3], line 51\u001b[0m, in \u001b[0;36mConvNet_2D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     49\u001b[0m linear \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLinear(x_flat, \u001b[39m256\u001b[39m)\n\u001b[1;32m     50\u001b[0m \u001b[39m# print(x.shape, x_flat)\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m x \u001b[39m=\u001b[39m linear(x)\n\u001b[1;32m     52\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden(x)\n\u001b[1;32m     53\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/net/home/store/home/cchen4/5F_EEG_DATA/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/net/home/store/home/cchen4/5F_EEG_DATA/.venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
     ]
    }
   ],
   "source": [
    "# run CNN\n",
    "# train neural net\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "accuracies = []\n",
    "\n",
    "for subj, features, labels in fileList:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size= 0.3) # 70% training 30% test\n",
    "    conv_net = ConvNet_2D().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    conv_net_optimizer = torch.optim.Adam(conv_net.parameters(), lr=0.001)\n",
    "    # Train the neural network\n",
    "    for epoch in range(50):\n",
    "        # print(\"epoch = \",epoch)\n",
    "        conv_net.train()\n",
    "        data = X_train\n",
    "        targets = y_train\n",
    "        data = torch.tensor(data.reshape(int(data.shape[0]), 1, data.shape[1], data.shape[2]), dtype=torch.float32) # reshape # of trial, 1 channel, # of samples\n",
    "        data = data.to(device)\n",
    "        targets = torch.tensor(targets, dtype=torch.int64)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        conv_net_predictions = conv_net(data)\n",
    "        conv_net_loss = criterion(conv_net_predictions, targets)\n",
    "\n",
    "        # Backward pass\n",
    "        conv_net_optimizer.zero_grad()\n",
    "        conv_net_loss.backward()\n",
    "        conv_net_optimizer.step()\n",
    "\n",
    "    # Evaluate the neural network\n",
    "    conv_net.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        data = X_test\n",
    "        targets = y_test\n",
    "        data = torch.tensor(data.reshape(int(data.shape[0]), 1, data.shape[1], data.shape[2]), dtype=torch.float32) # reshape # of trial, 1 channel, # of samples\n",
    "        data = data.to(device)\n",
    "        targets = torch.tensor(targets, dtype=torch.int64)\n",
    "        targets = targets.to(device)\n",
    "        conv_net_predictions = conv_net(data)\n",
    "        _, predicted = torch.max(conv_net_predictions.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "    print(f\"test accuracy {subj}= \",correct/total)\n",
    "    accuracies.append(correct/total)\n",
    "\n",
    "print(f'avg accuracy = {np.mean(accuracies)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy bp: 0.46511627906976744\n",
      "Accuracy cc: 0.6031746031746031\n",
      "Accuracy ht: 0.47619047619047616\n",
      "Accuracy jp: 0.5192307692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: class label 1 specified in weight is not found\n",
      "warning: class label 1 specified in weight is not found\n",
      "warning: class label 3 specified in weight is not found\n",
      "warning: class label 1 specified in weight is not found\n",
      "warning: class label 1 specified in weight is not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy mv: 0.5555555555555556\n",
      "Accuracy wc: 0.5405405405405406\n",
      "Accuracy zt: 0.4823529411764706\n",
      "Average accuracy:  0.5203087378483119\n"
     ]
    }
   ],
   "source": [
    "# SVM TIME WOOO\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "avg_acc = 0\n",
    "\n",
    "for subj, features, labels in fileList:\n",
    "    #features = csp_features[subj]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(np.reshape(features, (features.shape[0], -1)), labels, test_size= 0.3) # 70% training 30% test\n",
    "    \n",
    "    classifier = BaggingClassifier(svm.SVC(kernel='rbf'), n_estimators=20) # radial basis kernel; er i think they used gamma=0.2 ngl\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    avg_acc += metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Accuracy {subj}:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(\"Average accuracy: \", avg_acc/len(fileList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help :P\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def predict(y_train):\n",
    "    data = y_train\n",
    "    pred = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        data = data.to(device)\n",
    "        predictions = model(data)\n",
    "        _, predictions = predictions.max(1)\n",
    "    return predictions\n",
    "\n",
    "def evaluate(predictions, targets):\n",
    "    n_samples, n_correct = 0, 0\n",
    "    # print(targets.shape, predictions.shape)\n",
    "    # print(type(targets), targets.shape, type(predictions), len(predictions))\n",
    "    n_samples += targets.size(0)\n",
    "    n_correct += (predictions == targets).sum().item()\n",
    "    acc = n_correct / n_samples\n",
    "    print(f'accuracy = {acc}')\n",
    "    return acc\n",
    "\n",
    "def binary_confusion(y_pred, target):\n",
    "    # matrix represents [pred 0 targ 0, pred 0 targ 1] [pred 1 targ 0, pred 1 targ 1]\n",
    "    matrix = [[0, 0],[0, 0]]\n",
    "    for i in range(y_pred.shape[0]):\n",
    "        #zero stands for not thumb\n",
    "        if y_pred[i] == 0 and target[i] == 0:\n",
    "            matrix[0][0] += 1\n",
    "        elif y_pred[i] == 0 and target[i] == 1:\n",
    "            matrix[0][1] += 1\n",
    "        elif y_pred[i] == 1 and target[i] == 0:\n",
    "            matrix[1][0] += 1\n",
    "        elif y_pred[i] == 1 and target[i] == 1:\n",
    "            matrix[1][1] += 1\n",
    "    matrix = matrix/np.sum(matrix)\n",
    "    return matrix\n",
    "\n",
    "# final NeuralNet\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        ### FILL IN ### [10 POINTS]\n",
    "\n",
    "        self.hidden = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            # nn.Linear(121728, 256),\n",
    "            nn.Linear(43456, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4), # all features norefer\n",
    "            # nn.Linear(1408, 256), #pseudosampled featrues .\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128, 5),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        nn.Sequential(\n",
    "            nn.Linear(5, 16),\n",
    "            nn.Linear(16, 32),\n",
    "            nn.Linear(32, 5)\n",
    "        )\n",
    "        return x\n",
    "    \n",
    "# ConvNet_Finger\n",
    "\n",
    "class ConvNet_Finger(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet_Finger, self).__init__()\n",
    "        ### FILL IN ### [10 POINTS]\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, (7, 3)),\n",
    "            nn.ReLU(), \n",
    "            #nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(8, 16, (5, 3)),\n",
    "            nn.Conv2d(16, 32, (3, 3)),\n",
    "            nn.ReLU(),\n",
    "            #nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            #nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.hidden = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            # nn.Linear(121728, 256),\n",
    "            nn.Linear(43456, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4), # all features norefer\n",
    "            # nn.Linear(1408, 256), #pseudosampled featrues .\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128, 2),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### FILL IN ### [5 POINTS]\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        # x = self.conv3(x)\n",
    "        x = self.hidden(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (206x1081472 and 43456x256)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     44\u001b[0m \u001b[39m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m predictions \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m     46\u001b[0m loss \u001b[39m=\u001b[39m criterion(predictions, targets)\n\u001b[1;32m     48\u001b[0m \u001b[39m# Backward pass\u001b[39;00m\n",
      "File \u001b[0;32m/net/home/store/home/cchen4/5F_EEG_DATA/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[15], line 118\u001b[0m, in \u001b[0;36mConvNet_Finger.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    116\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x)\n\u001b[1;32m    117\u001b[0m \u001b[39m# x = self.conv3(x)\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhidden(x)\n\u001b[1;32m    119\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/net/home/store/home/cchen4/5F_EEG_DATA/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/net/home/store/home/cchen4/5F_EEG_DATA/.venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/net/home/store/home/cchen4/5F_EEG_DATA/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/net/home/store/home/cchen4/5F_EEG_DATA/.venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (206x1081472 and 43456x256)"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "batch_size = 32\n",
    "dropout = 0.2\n",
    "n_epochs = 30\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-6\n",
    "\n",
    "torch.cuda.set_device(4)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "sm = SMOTE()\n",
    "\n",
    "# train neural net\n",
    "accuracies = []\n",
    "for subj, features, labels in fileList:\n",
    "    ch = features.shape[1]\n",
    "    input_shape = (-1, 1, ch, t)\n",
    "    new_features = []\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size= 0.3) # 70% training 30% test\n",
    "    for finger in range(5):\n",
    "        y_train_ = np.where(y_train == finger, 1, 0)\n",
    "        y_test_ = np.where(y_test == finger, 1, 0)\n",
    "        X_res = X_train.reshape((X_train.shape[0], -1))\n",
    "        X_res, y_res = sm.fit_resample(X_res, y_train_)\n",
    "        X_res = X_res.reshape((X_res.shape[0], ch, -1))\n",
    "\n",
    "        model = ConvNet_Finger().to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        # Train the neural network\n",
    "\n",
    "        model.train()\n",
    "        data = X_res\n",
    "        targets = y_res\n",
    "        data = torch.tensor(data.reshape(int(data.shape[0]), 1, data.shape[1], data.shape[2]), dtype=torch.float32) # reshape # of trial, 1 channel, # of samples\n",
    "        data = data.to(device)\n",
    "        targets = torch.tensor(targets, dtype=torch.int64)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            # print(\"epoch = \",epoch)\n",
    "            model.train()\n",
    "\n",
    "            # Forward pass\n",
    "            predictions = model(data)\n",
    "            loss = criterion(predictions, targets)\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        torch.save(model.state_dict(), f'pickles/models/{subj}_finger_{finger}.pt')\n",
    "        \n",
    "        pred = predict(torch.as_tensor(X_train.reshape(input_shape), dtype=torch.float32).to(device))\n",
    "        new_features.append(pred*finger)\n",
    "    new_features = torch.stack(new_features)\n",
    "    features = torch.transpose(torch.tensor(new_features, dtype=torch.float32), 0, 1).to(device).requires_grad_(True)\n",
    "    \n",
    "    # final NeuralNet\n",
    "    model = NeuralNet().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Train the neural network\n",
    "    model.train()\n",
    "    data = features\n",
    "    targets = torch.tensor(y_train, dtype=torch.int64).to(device)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        # print(\"epoch = \",epoch)\n",
    "        model.train()\n",
    "\n",
    "        # Forward pass\n",
    "        predictions = model(data)\n",
    "        loss = criterion(predictions, targets)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    torch.save(model.state_dict(), f'pickles/models/{subj}_final.pt')\n",
    "\n",
    "    print(f'trained {subj} {finger}')\n",
    "    new_features = []\n",
    "\n",
    "    for finger in range(5):\n",
    "        model = ConvNet_Finger().to(device)\n",
    "        criterion = nn.CrossEntropyLoss\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        model.load_state_dict(torch.load(f'pickles/models/{subj}_finger_{finger}.pt'))\n",
    "\n",
    "        y_res = np.where(y_test == finger, 1, 0)\n",
    "        y_res = torch.tensor(y_res, dtype=torch.int64).to(device)\n",
    "        pred = predict(torch.tensor(X_test.reshape(input_shape), dtype=torch.float32).to(device))\n",
    "        print(f'accuracy {subj} finger {finger} = {evaluate(pred, y_res)} {binary_confusion(pred, y_res)})')\n",
    "        new_features.append(pred*finger)\n",
    "\n",
    "\n",
    "    new_features = torch.stack(new_features)\n",
    "    features = torch.transpose(torch.tensor(new_features, dtype=torch.float32), 0, 1).to(device).requires_grad_(True)\n",
    "    \n",
    "    model = NeuralNet().to(device)\n",
    "    model.load_state_dict(torch.load(f'pickles/models/{subj}_final.pt'))\n",
    "    acc = evaluate(predict(features), torch.tensor(y_test, dtype=torch.int64).to(device))\n",
    "    print(f'FINAL accuracy {subj} = {acc} ***************************************')\n",
    "    accuracies.append(acc)\n",
    "\n",
    "print(f'avg accuracy = {np.mean(accuracies)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
