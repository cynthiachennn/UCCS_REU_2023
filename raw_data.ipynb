{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the raw data :')\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import re\n",
    "import random\n",
    "\n",
    "# some hyperparameter type things :)\n",
    "sr = 200\n",
    "t = 200\n",
    "ch = 19\n",
    "affix = '_raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_features = {}\n",
    "raw_labels = {}\n",
    "\n",
    "for subj in [('A_405', ''), ('A_408', '_HFREQ'), ('B_110', ''), ('B_309', '_HFREQ'), ('B_311', '_HFREQ'), ('B_316', ''), ('C_204', ''), ('C_429', '_HFREQ'), ('E_321', '_HFREQ'), ('E_415', '_HFREQ'), ('E_429', '_HFREQ'), ('F_027', ''), ('F_209', ''), ('F_210', '_HFREQ'), ('G_413', '_HFREQ'), ('G_428', '_HFREQ'), ('H_804', '_HFREQ'), ('I_719', '_HFREQ'), ('I_723', '_HFREQ')]:\n",
    "    # print(subj[0])\n",
    "    sr = 1000 if subj[1] == '_HFREQ' else 200\n",
    "    mat = scipy.io.loadmat(f'preprocessing/raw_data/{subj[0]}{subj[1]}.mat')\n",
    "    data = mat['o'][0][0][5].T\n",
    "    data = np.delete(data, [10, 11, 21], axis = 0)\n",
    "\n",
    "    if sr == 1000: data = scipy.signal.resample(data, int(data.shape[1]/5), axis = 1)\n",
    "\n",
    "    events = pd.read_csv(f\"preprocessing/{subj[0]}_events.txt\", sep=\"\\t\").drop('number', axis=1)\n",
    "    events = events[['latency', 'urevent', 'type']].to_numpy()\n",
    "    events = mne.pick_events(events, include=[1, 2, 3, 4, 5]) # should replace this with a numpy function lol\n",
    "\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    for event in events:\n",
    "        time = int(event[0])\n",
    "        if sr == 1000: time = int(time/5)\n",
    "        type = int(event[2])\n",
    "        features.append([data[i][time:time+t] for i in range(ch)])\n",
    "        labels.append(type - 1)\n",
    "\n",
    "    raw_features[subj[0]], raw_labels[subj[0]] = np.array(features), np.array(labels)\n",
    "\n",
    "subjList = ['A_405', 'A_408', 'B_110', 'B_309', 'B_311', 'B_316', 'C_204', 'C_429', 'E_321', 'E_415', 'E_429', 'F_027', 'F_209', 'F_210', 'G_413', 'G_428', 'H_804', 'I_719', 'I_723']\n",
    "fileList = []\n",
    "\n",
    "for letter in ['A', 'B', 'C', 'E', 'F', 'G', 'H', 'I']:\n",
    "    r = re.compile(f'{letter}_d*')\n",
    "    subjects = list(filter(r.match, subjList))\n",
    "    # print(subjects)\n",
    "    subjects = [(raw_features[x], raw_labels[x]) for x in subjects]\n",
    "    fileName = f'subj_{letter}'\n",
    "    _features = np.concatenate([features for features, labels in subjects])\n",
    "    _labels = np.concatenate([labels for features, labels in subjects])\n",
    "\n",
    "    _features = np.array(_features).reshape(-1, 19, t)\n",
    "    _labels = np.array(_labels).reshape(-1)\n",
    "    fileList.append((fileName, _features, _labels))\n",
    "\n",
    "for subj, file, labels in fileList:\n",
    "    np.save(f'pickles/{subj}_features{affix}', file)\n",
    "    np.save(f'pickles/{subj}_labels{affix}', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fileList' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m subj, file, labels \u001b[39min\u001b[39;00m fileList:\n\u001b[1;32m      2\u001b[0m    np\u001b[39m.\u001b[39msave(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpickles/\u001b[39m\u001b[39m{\u001b[39;00msubj\u001b[39m}\u001b[39;00m\u001b[39m_features\u001b[39m\u001b[39m{\u001b[39;00maffix\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m, file)\n\u001b[1;32m      3\u001b[0m    np\u001b[39m.\u001b[39msave(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpickles/\u001b[39m\u001b[39m{\u001b[39;00msubj\u001b[39m}\u001b[39;00m\u001b[39m_labels\u001b[39m\u001b[39m{\u001b[39;00maffix\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m, labels)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fileList' is not defined"
     ]
    }
   ],
   "source": [
    "for subj, file, labels in fileList:\n",
    "   np.save(f'pickles/{subj}_features{affix}', file)\n",
    "   np.save(f'pickles/{subj}_labels{affix}', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_features = {}\n",
    "raw_labels = {}\n",
    "\n",
    "for subj in [('A_405', ''), ('A_408', '_HFREQ'), ('B_110', ''), ('B_309', '_HFREQ'), ('B_311', '_HFREQ'), ('B_316', ''), ('C_204', ''), ('C_429', '_HFREQ'), ('E_321', '_HFREQ'), ('E_415', '_HFREQ'), ('E_429', '_HFREQ'), ('F_027', ''), ('F_209', ''), ('F_210', '_HFREQ'), ('G_413', '_HFREQ'), ('G_428', '_HFREQ'), ('H_804', '_HFREQ'), ('I_719', '_HFREQ'), ('I_723', '_HFREQ')]:\n",
    "    # print(subj[0])\n",
    "    sr = 1000 if subj[1] == '_HFREQ' else 200\n",
    "    mat = scipy.io.loadmat(f'preprocessing/raw_data/{subj[0]}{subj[1]}.mat')\n",
    "    data = mat['o'][0][0][5].T\n",
    "    data = np.delete(data, [10, 11, 21], axis = 0)\n",
    "\n",
    "    if sr == 1000: data = scipy.signal.resample(data, int(data.shape[1]/5), axis = 1)\n",
    "\n",
    "    events = pd.read_csv(f\"preprocessing/{subj[0]}_events.txt\", sep=\"\\t\").drop('number', axis=1)\n",
    "    events = events[['latency', 'urevent', 'type']].to_numpy()\n",
    "    events = mne.pick_events(events, include=[1, 2, 3, 4, 5]) # should replace this with a numpy function lol\n",
    "\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    for event in events:\n",
    "        time = int(event[0])\n",
    "        if sr == 1000: time = int(time/5)\n",
    "        type = int(event[2])\n",
    "        features.append([data[i][time:time+t] for i in range(ch)])\n",
    "        features.append([data[i][time+50:time+t+50] for i in range(ch)])\n",
    "        features.append([data[i][time+100:time+t+100] for i in range(ch)])\n",
    "        labels.append(type - 1)\n",
    "        labels.append(type - 1)\n",
    "        labels.append(type - 1)\n",
    "\n",
    "    raw_features[subj[0]], raw_labels[subj[0]] = np.array(features), np.array(labels)\n",
    "\n",
    "subjList = ['A_405', 'A_408', 'B_110', 'B_309', 'B_311', 'B_316', 'C_204', 'C_429', 'E_321', 'E_415', 'E_429', 'F_027', 'F_209', 'F_210', 'G_413', 'G_428', 'H_804', 'I_719', 'I_723']\n",
    "fileList = []\n",
    "\n",
    "for letter in ['A', 'B', 'C', 'E', 'F', 'G', 'H', 'I']:\n",
    "    r = re.compile(f'{letter}_d*')\n",
    "    subjects = list(filter(r.match, subjList))\n",
    "    # print(subjects)\n",
    "    subjects = [(raw_features[x], raw_labels[x]) for x in subjects]\n",
    "    fileName = f'subj_{letter}'\n",
    "    _features = np.concatenate([features for features, labels in subjects])\n",
    "    _labels = np.concatenate([labels for features, labels in subjects])\n",
    "\n",
    "    _features = np.array(_features).reshape(-1, 19, t)\n",
    "    _labels = np.array(_labels).reshape(-1)\n",
    "    fileList.append((fileName, _features, _labels))\n",
    "\n",
    "# for subj, file, labels in fileList:\n",
    "#     np.save(f'pickles/{subj}_features{affix}', file)\n",
    "#     np.save(f'pickles/{subj}_labels{affix}', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from .pkl files (\"raw\")\n",
    "raw_features = {}\n",
    "raw_labels = {}\n",
    "fileList = []\n",
    "\n",
    "for letter in ['A', 'B', 'C', 'E', 'F', 'G', 'H', 'I']: \n",
    "    raw_features[f'subj_{letter}'] = np.load(f'pickles/subj_{letter}_features{affix}.npy')\n",
    "    raw_labels[f'subj_{letter}'] = np.load(f'pickles/subj_{letter}_labels{affix}.npy').reshape(-1)\n",
    "    fileList.append((f'subj_{letter}', raw_features[f'subj_{letter}'], raw_labels[f'subj_{letter}']))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "features extraction ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pseudosampling\n",
    "\n",
    "window = 100 # window size\n",
    "strides = [25, 10, 10, 5, 5, 10, 10, 25, 0] # step size (but actually it's better to make it BELL CURVE OMGGGGGGG (for overlap % maybe then...))\n",
    "# strides = [50, 25, 25, 25, 25, 50] #this is if samples are 400 total \n",
    "pseudosampled_features = {}\n",
    "pseudosampled_labels = {}\n",
    "\n",
    "for idx, (subj, features, labels) in enumerate(fileList):\n",
    "    _features = np.empty((features.shape[0], features.shape[1]* len(strides) + 1, window))\n",
    "    for trial_i in range(len(labels)):\n",
    "        start = 0\n",
    "        for s in strides:\n",
    "            end = start + window\n",
    "            for channel_i in range(ch):\n",
    "                #print(features[trial_i][channel_i].shape, start, end, window)\n",
    "                _features[trial_i][channel_i] = features[trial_i][channel_i][start:end]\n",
    "            start += s\n",
    "    pseudosampled_features[subj] = _features\n",
    "    pseudosampled_labels[subj] = labels\n",
    "    fileList[idx] = (subj, _features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do fft for everyone :)\n",
    "from scipy import fftpack\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sample_freqs = fftpack.fftfreq(t) # since all samples are the same, sample freqs are the same\n",
    "\n",
    "fft_features = {}\n",
    "fft_labels = {}\n",
    "\n",
    "for subj, features, labels in fileList:\n",
    "    # file.event_id = {'thumb':1, 'index':2, 'middle':3, 'ring':4, 'pinkie':5}\n",
    "    # conditions = ['thumb']\n",
    "    fft_features[subj] = np.zeros((labels.shape[0], ch, int(t/2)))\n",
    "    for trial_i in range(labels.shape[0]): #for each event\n",
    "        fft = np.zeros((ch, int(t/2)))\n",
    "        for channel_i in range(ch):\n",
    "            sample = features[trial_i][channel_i]\n",
    "            power = sig_fft = fftpack.fft(sample)\n",
    "            power = np.abs(sig_fft)\n",
    "            sample_freq = fftpack.fftfreq(sample.size)\n",
    "            fft[channel_i] = power[0:int(power.size/2)]\n",
    "        fft_features[subj][trial_i] = fft\n",
    "    fft_labels[subj] = labels\n",
    "    features = fft_features[subj]\n",
    "#   print(f'{subj}: {file.events.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get CSP features :D\n",
    "from mne.decoding import CSP\n",
    "\n",
    "file = mne.io.read_raw_eeglab('preprocessing/A_405_clean.set', verbose=False)\n",
    "\n",
    "csp_features = {}\n",
    "csp_labels = {}\n",
    "\n",
    "for subj, features, labels in fileList:\n",
    "    csp = CSP(n_components=5, reg=None, log=True)\n",
    "    labels = raw_labels[subj]\n",
    "\n",
    "    csp_features[subj] = csp.fit_transform(features, labels)\n",
    "    csp_labels[subj] = labels\n",
    "\n",
    "    csp.plot_filters(file.info, title='CSP patterns for %s' % subj)    \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2D CNN w/ Adham's recommendations\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class ConvNet_2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet_2D, self).__init__()\n",
    "        ### FILL IN ### [10 POINTS]\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, (7, 3)),\n",
    "            nn.ReLU(), \n",
    "            #nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(8, 16, (5, 3)),\n",
    "            nn.Conv2d(16, 32, (3, 3)),\n",
    "            nn.ReLU(),\n",
    "            #nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            #nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.hidden = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            # nn.Linear(121728, 256),\n",
    "            nn.Linear(43456, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4), #\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128, 5),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### FILL IN ### [5 POINTS]\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        # x = self.conv3(x)\n",
    "        x = self.hidden(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified 2D CNN :D\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class ConvNet_2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet_2D, self).__init__()\n",
    "        ### FILL IN ### [10 POINTS]\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, (7, 7)),\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, (5, 7)),\n",
    "            #nn.Conv2d(16, 32, (3, 7)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "\n",
    "        self.hidden = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            # nn.Linear(121728, 256),\n",
    "            nn.Linear(24960, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4), #\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128, 5),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### FILL IN ### [5 POINTS]\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        # x = self.conv3(x)\n",
    "        x = self.hidden(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[1;32m      6\u001b[0m \u001b[39m# train neural net\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m torch\u001b[39m.\u001b[39;49mcuda\u001b[39m.\u001b[39;49mset_device(\u001b[39m5\u001b[39;49m)\n\u001b[1;32m      8\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[39m# torch.manual_seed(42)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m# np.random.seed(42)\u001b[39;00m\n",
      "File \u001b[0;32m~/cynthia/lib/python3.10/site-packages/torch/cuda/__init__.py:350\u001b[0m, in \u001b[0;36mset_device\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    348\u001b[0m device \u001b[39m=\u001b[39m _get_device_index(device)\n\u001b[1;32m    349\u001b[0m \u001b[39mif\u001b[39;00m device \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 350\u001b[0m     torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_cuda_setDevice(device)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# run CNN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "# train neural net\n",
    "torch.cuda.set_device(5)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# torch.manual_seed(42)\n",
    "# np.random.seed(42)\n",
    "device = 'cpu'\n",
    "accuracies = []\n",
    "\n",
    "for subj, features, labels in fileList:\n",
    "    # features = pseudosampled_features[subj]\n",
    "    # labels = pseudosampled_labels[subj]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size= 0.2) # 70% training 30% test\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size= 0.2) # 70% training 30% test\n",
    "    conv_net = ConvNet_2D().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    conv_net_optimizer = torch.optim.Adam(conv_net.parameters(), lr=0.001)\n",
    "    # Train the neural network\n",
    "    train_acc = 0\n",
    "    for epoch in range(100):\n",
    "        # print(\"epoch = \",epoch)\n",
    "        conv_net.train()\n",
    "        data = X_train\n",
    "        targets = y_train\n",
    "        data = torch.tensor(data.reshape(int(data.shape[0]), 1, data.shape[1], data.shape[2]), dtype=torch.float32) # reshape # of trial, 1 channel, # of samples\n",
    "        data = data.to(device)\n",
    "        targets = torch.tensor(targets, dtype=torch.int64)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        conv_net_predictions = conv_net(data)\n",
    "        conv_net_loss = criterion(conv_net_predictions, targets)\n",
    "\n",
    "        total, correct = 0, 0\n",
    "        _, predicted = torch.max(conv_net_predictions.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "        \n",
    "        # Backward pass\n",
    "        conv_net_optimizer.zero_grad()\n",
    "        conv_net_loss.backward()\n",
    "        conv_net_optimizer.step()\n",
    "        train_acc = correct/total\n",
    "\n",
    "    print(f\"train accuracy {subj}= \", train_acc) \n",
    "\n",
    "    # Evaluate the neural network\n",
    "    conv_net.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        data = X_test\n",
    "        targets = y_test\n",
    "        data = torch.tensor(data.reshape(int(data.shape[0]), 1, data.shape[1], data.shape[2]), dtype=torch.float32) # reshape # of trial, 1 channel, # of samples\n",
    "        data = data.to(device)\n",
    "        targets = torch.tensor(targets, dtype=torch.int64)\n",
    "        targets = targets.to(device)\n",
    "        conv_net_predictions = conv_net(data)\n",
    "        _, predicted = torch.max(conv_net_predictions.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "    print(f\"test accuracy {subj}= \",correct/total, '****************************')\n",
    "    accuracies.append(correct/total)\n",
    "\n",
    "print(f'avg accuracy = {np.mean(accuracies)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm results ?\n",
      " 0.4686593618805314 \n",
      "cnn results ? \n",
      " 0.4719110152584027 \n",
      "original conformer results ? \n",
      " 0.5143263042226336 \n",
      "so i deleted all my results by accident but here is conformer with (1, 30) (1, 5) for the avg pooling layr\n",
      " 0.537115621894141\n"
     ]
    }
   ],
   "source": [
    "print('svm results ?\\n',\n",
    "    sum([0.395985401459854, 0.47465034965034963, 0.5421052631578948, 0.5941520467836258, 0.42526071842410196, 0.4868651488616462, 0.3285198555956679, 0.5017361111111112])/8,\n",
    "    '\\ncnn results ? \\n',\n",
    "    sum([0.3852971845672575, 0.4629299272156414, 0.5622627998567848, 0.6061582527747941, 0.5184808570009697, 0.46320454626684315, 0.33095115302438655, 0.44600340136054417])/8,\n",
    "    '\\noriginal conformer results ? \\n',\n",
    "    sum([0.39635781319827196, 0.5261345797060083, 0.6215180809165771, 0.6468074949277957, 0.5315581620829096, 0.48086064548411306, 0.3558535327488396, 0.5555201247165534])/8,\n",
    "    '\\nso i deleted all my results by accident but here is conformer with (1, 30) (1, 5) for the avg pooling layr\\n',\n",
    "    sum([0.3898406077759572, 0.5644355644355643, 0.6309344790547797, 0.6864781000119345, 0.5636011067231064, 0.5654240680510381, 0.35961099241140504, 0.5366000566893423])/8,\n",
    "    '\\nn_heads = 16, kernels 1, 17 and 1, 13\\n',\n",
    "    sum([0.415499776552957, 0.5645782788639931, 0.6829573934837094, 0.720420097863707, 0.5631990919195025, 0.5254655277172164, 0.3915125617033816, 0.5781250000000001])/8\n",
    "    '\\n'\n",
    ")\n",
    "\n",
    "# different configurations and their performace:\n",
    "\n",
    "# haha i just peaked look at this shi:\n",
    "# final average acc: 0.5691622302337598\n",
    "# best accuracies [0.49635036496350365, 0.5856643356643356, 0.7175438596491228, 0.7345029239766082, 0.6118192352259559, 0.5691768826619965, 0.40794223826714804, 0.6354166666666666]\n",
    "# average accuracies [0.46920154923283164, 0.5686813186813185, 0.6904403866809883, 0.7048335123523094, 0.5979615484664316, 0.5370456413738876, 0.37515656081927345, 0.6099773242630385]\n",
    "# final accuracies [0.4744525547445255, 0.5611888111888111, 0.6912280701754386, 0.7087719298245614, 0.5955967555040557, 0.5341506129597198, 0.3898916967509025, 0.6111111111111112] avg: 0.5707989427823907\n",
    "\n",
    "\n",
    "\n",
    "# normal CNN, 200 point raw data samples, accuracy of about 46-49%\n",
    "# normal CNN, 100 point pseudosampled off of 200 point raw data samples, accuracy of about 45% ???**\n",
    "# normal CNN, 100 point pseudosampled off of 400 point raw data samples, accuracy of about 20- 30% .. bad....\n",
    "# normal CNN, 400 point raw data samples, acc = slightly less than 200 pt data samples.. :(\n",
    "# try taking 400 point raw data but pseudosample them into 200 point samples = 20-30% acc...D:\n",
    "# normal CNN, 200 point raw data samples but start 50 points after onset of signal ????\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN transfer learning version\n",
    "# train neural net\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "conv_net = ConvNet_2D().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "conv_net_optimizer = torch.optim.Adam(conv_net.parameters(), lr=0.001)\n",
    "\n",
    "random.shuffle(fileList)\n",
    "\n",
    "for subj, features, labels in fileList[0:-1]:\n",
    "    # Train the neural network\n",
    "    for epoch in range(30):\n",
    "        # print(\"epoch = \",epoch)\n",
    "        conv_net.train()\n",
    "        data = features\n",
    "        targets = labels\n",
    "        data = torch.tensor(data.reshape(int(data.shape[0]), 1, data.shape[1], data.shape[2]), dtype=torch.float32) # reshape # of trial, 1 channel, # of samples\n",
    "        data = data.to(device)\n",
    "        targets = torch.tensor(targets, dtype=torch.int64)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        conv_net_predictions = conv_net(data)\n",
    "        conv_net_loss = criterion(conv_net_predictions, targets)\n",
    "\n",
    "        # Backward pass\n",
    "        conv_net_optimizer.zero_grad()\n",
    "        conv_net_loss.backward()\n",
    "        conv_net_optimizer.step()\n",
    "\n",
    "    # Evaluate the neural network\n",
    "    conv_net.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        data = fileList[-1][1]\n",
    "        targets = fileList[-1][2]\n",
    "        data = torch.tensor(data.reshape(int(data.shape[0]), 1, data.shape[1], data.shape[2]), dtype=torch.float32) # reshape # of trial, 1 channel, # of samples\n",
    "        data = data.to(device)\n",
    "        targets = torch.tensor(targets, dtype=torch.int64)\n",
    "        targets = targets.to(device)\n",
    "        conv_net_predictions = conv_net(data)\n",
    "        _, predicted = torch.max(conv_net_predictions.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "    print(f\"test accuracy {subj} = \",correct/total)\n",
    "\n",
    "with torch.no_grad():\n",
    "    data = fileList[-1][1]\n",
    "    targets = fileList[-1][2]\n",
    "    data = torch.tensor(data.reshape(int(data.shape[0]), 1, data.shape[1], data.shape[2]), dtype=torch.float32) # reshape # of trial, 1 channel, # of samples\n",
    "    data = data.to(device)\n",
    "    targets = torch.tensor(targets, dtype=torch.int64)\n",
    "    targets = targets.to(device)\n",
    "    conv_net_predictions = conv_net(data)\n",
    "    _, predicted = torch.max(conv_net_predictions.data, 1)\n",
    "    total += targets.size(0)\n",
    "    correct += (predicted == targets).sum().item()\n",
    "print(\"test accuracy = \",correct/total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy subj_A: 0.3594890510948905\n",
      "Accuracy subj_B: 0.42132867132867136\n",
      "Accuracy subj_C: 0.512280701754386\n",
      "Accuracy subj_E: 0.5883040935672514\n",
      "Accuracy subj_F: 0.3383545770567787\n",
      "Accuracy subj_G: 0.4080560420315236\n",
      "Accuracy subj_H: 0.36462093862815886\n",
      "Accuracy subj_I: 0.4201388888888889\n",
      "Average accuracy:  0.4265716205438187\n"
     ]
    }
   ],
   "source": [
    "# SVM TIME WOOO\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "avg_acc = 0\n",
    "\n",
    "for subj, features, labels in fileList:\n",
    "    #features = csp_features[subj]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(np.reshape(features, (features.shape[0], -1)), labels, test_size= 0.3) # 70% training 30% test\n",
    "    \n",
    "    classifier = BaggingClassifier(svm.SVC(kernel='rbf'), n_estimators=20) # radial basis kernel; er i think they used gamma=0.2 ngl\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    avg_acc += metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Accuracy {subj}:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(\"Average accuracy: \", avg_acc/len(fileList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-mlogloss:1.52517\ttrain-mlogloss:1.40650\n",
      "[1]\teval-mlogloss:1.51494\ttrain-mlogloss:1.29468\n",
      "[2]\teval-mlogloss:1.51629\ttrain-mlogloss:1.20004\n",
      "[3]\teval-mlogloss:1.52162\ttrain-mlogloss:1.12533\n",
      "[4]\teval-mlogloss:1.51152\ttrain-mlogloss:1.05465\n",
      "[5]\teval-mlogloss:1.50991\ttrain-mlogloss:0.98481\n",
      "[6]\teval-mlogloss:1.53886\ttrain-mlogloss:0.92206\n",
      "[7]\teval-mlogloss:1.55886\ttrain-mlogloss:0.86647\n",
      "[8]\teval-mlogloss:1.55472\ttrain-mlogloss:0.81264\n",
      "[9]\teval-mlogloss:1.56800\ttrain-mlogloss:0.76295\n",
      "Accuracy subj_A: 0.3284671532846715\n",
      "[0]\teval-mlogloss:1.56228\ttrain-mlogloss:1.49020\n",
      "[1]\teval-mlogloss:1.54860\ttrain-mlogloss:1.41134\n",
      "[2]\teval-mlogloss:1.54483\ttrain-mlogloss:1.34992\n",
      "[3]\teval-mlogloss:1.52347\ttrain-mlogloss:1.29372\n",
      "[4]\teval-mlogloss:1.52395\ttrain-mlogloss:1.24834\n",
      "[5]\teval-mlogloss:1.52076\ttrain-mlogloss:1.20347\n",
      "[6]\teval-mlogloss:1.50856\ttrain-mlogloss:1.16299\n",
      "[7]\teval-mlogloss:1.50494\ttrain-mlogloss:1.12515\n",
      "[8]\teval-mlogloss:1.51138\ttrain-mlogloss:1.08954\n",
      "[9]\teval-mlogloss:1.51913\ttrain-mlogloss:1.05626\n",
      "Accuracy subj_B: 0.34702797202797203\n",
      "[0]\teval-mlogloss:1.53462\ttrain-mlogloss:1.41414\n",
      "[1]\teval-mlogloss:1.49453\ttrain-mlogloss:1.27183\n",
      "[2]\teval-mlogloss:1.44743\ttrain-mlogloss:1.16128\n",
      "[3]\teval-mlogloss:1.43065\ttrain-mlogloss:1.06750\n",
      "[4]\teval-mlogloss:1.42026\ttrain-mlogloss:0.97730\n",
      "[5]\teval-mlogloss:1.41673\ttrain-mlogloss:0.90095\n",
      "[6]\teval-mlogloss:1.41980\ttrain-mlogloss:0.83273\n",
      "[7]\teval-mlogloss:1.43071\ttrain-mlogloss:0.76822\n",
      "[8]\teval-mlogloss:1.42485\ttrain-mlogloss:0.71193\n",
      "[9]\teval-mlogloss:1.42102\ttrain-mlogloss:0.66130\n",
      "Accuracy subj_C: 0.40350877192982454\n",
      "[0]\teval-mlogloss:1.46596\ttrain-mlogloss:1.40155\n",
      "[1]\teval-mlogloss:1.36666\ttrain-mlogloss:1.26467\n",
      "[2]\teval-mlogloss:1.29714\ttrain-mlogloss:1.15982\n",
      "[3]\teval-mlogloss:1.25773\ttrain-mlogloss:1.06755\n",
      "[4]\teval-mlogloss:1.21445\ttrain-mlogloss:0.99414\n",
      "[5]\teval-mlogloss:1.19076\ttrain-mlogloss:0.92213\n",
      "[6]\teval-mlogloss:1.17157\ttrain-mlogloss:0.86093\n",
      "[7]\teval-mlogloss:1.16224\ttrain-mlogloss:0.80419\n",
      "[8]\teval-mlogloss:1.15524\ttrain-mlogloss:0.75510\n",
      "[9]\teval-mlogloss:1.14362\ttrain-mlogloss:0.71200\n",
      "Accuracy subj_E: 0.5321637426900585\n",
      "[0]\teval-mlogloss:1.60619\ttrain-mlogloss:1.52287\n",
      "[1]\teval-mlogloss:1.60867\ttrain-mlogloss:1.45216\n",
      "[2]\teval-mlogloss:1.61132\ttrain-mlogloss:1.38529\n",
      "[3]\teval-mlogloss:1.60253\ttrain-mlogloss:1.32459\n",
      "[4]\teval-mlogloss:1.61125\ttrain-mlogloss:1.26980\n",
      "[5]\teval-mlogloss:1.61572\ttrain-mlogloss:1.21843\n",
      "[6]\teval-mlogloss:1.61920\ttrain-mlogloss:1.17144\n",
      "[7]\teval-mlogloss:1.62875\ttrain-mlogloss:1.12606\n",
      "[8]\teval-mlogloss:1.62813\ttrain-mlogloss:1.08394\n",
      "[9]\teval-mlogloss:1.64116\ttrain-mlogloss:1.04534\n",
      "Accuracy subj_F: 0.28968713789107764\n",
      "[0]\teval-mlogloss:1.46815\ttrain-mlogloss:1.38424\n",
      "[1]\teval-mlogloss:1.41348\ttrain-mlogloss:1.24252\n",
      "[2]\teval-mlogloss:1.38898\ttrain-mlogloss:1.14028\n",
      "[3]\teval-mlogloss:1.37242\ttrain-mlogloss:1.05734\n",
      "[4]\teval-mlogloss:1.35327\ttrain-mlogloss:0.97925\n",
      "[5]\teval-mlogloss:1.33825\ttrain-mlogloss:0.90944\n",
      "[6]\teval-mlogloss:1.36475\ttrain-mlogloss:0.84570\n",
      "[7]\teval-mlogloss:1.37866\ttrain-mlogloss:0.78982\n",
      "[8]\teval-mlogloss:1.38068\ttrain-mlogloss:0.73635\n",
      "[9]\teval-mlogloss:1.38573\ttrain-mlogloss:0.68687\n",
      "Accuracy subj_G: 0.4115586690017513\n",
      "[0]\teval-mlogloss:1.57114\ttrain-mlogloss:1.35589\n",
      "[1]\teval-mlogloss:1.56096\ttrain-mlogloss:1.20769\n",
      "[2]\teval-mlogloss:1.56340\ttrain-mlogloss:1.06709\n",
      "[3]\teval-mlogloss:1.56645\ttrain-mlogloss:0.95247\n",
      "[4]\teval-mlogloss:1.59535\ttrain-mlogloss:0.84846\n",
      "[5]\teval-mlogloss:1.61024\ttrain-mlogloss:0.76914\n",
      "[6]\teval-mlogloss:1.61704\ttrain-mlogloss:0.68745\n",
      "[7]\teval-mlogloss:1.60909\ttrain-mlogloss:0.62016\n",
      "[8]\teval-mlogloss:1.60293\ttrain-mlogloss:0.55817\n",
      "[9]\teval-mlogloss:1.59781\ttrain-mlogloss:0.50340\n",
      "Accuracy subj_H: 0.35379061371841153\n",
      "[0]\teval-mlogloss:1.48448\ttrain-mlogloss:1.34383\n",
      "[1]\teval-mlogloss:1.41951\ttrain-mlogloss:1.20699\n",
      "[2]\teval-mlogloss:1.37472\ttrain-mlogloss:1.10379\n",
      "[3]\teval-mlogloss:1.37044\ttrain-mlogloss:1.01782\n",
      "[4]\teval-mlogloss:1.36294\ttrain-mlogloss:0.93864\n",
      "[5]\teval-mlogloss:1.34629\ttrain-mlogloss:0.86891\n",
      "[6]\teval-mlogloss:1.33715\ttrain-mlogloss:0.80876\n",
      "[7]\teval-mlogloss:1.33291\ttrain-mlogloss:0.75226\n",
      "[8]\teval-mlogloss:1.33622\ttrain-mlogloss:0.70470\n",
      "[9]\teval-mlogloss:1.33574\ttrain-mlogloss:0.66024\n",
      "Accuracy subj_I: 0.4409722222222222\n",
      "Avg Accuracy: 0.3883970353457487\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "avg_acc = 0\n",
    "for subj, features, labels in fileList:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(np.reshape(features, (features.shape[0], -1)), labels, test_size= 0.3) # 70% training 30% test\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "    num_rounds = 10\n",
    "    param = {'max_depth': 2, 'eta': 1, 'objective': 'multi:softmax', 'num_class': 5}\n",
    "    watchlist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "\n",
    "    bst = xgb.train(param, dtrain, num_boost_round=num_rounds, evals=watchlist)\n",
    "    y_pred = bst.predict(dtest)\n",
    "    avg_acc += metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Accuracy {subj}:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(f'Avg Accuracy: {avg_acc/len(fileList)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest ?\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "for subj, features, labels in fileList:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size= 0.3) # 70% training 30% test\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators = 100)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    print(f\"Accuracy {subj}:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN + LSTM :D\n",
    "#2D CNN w/ Adham's recommendations\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class Conv_LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Conv_LSTM, self).__init__()\n",
    "        ### FILL IN ### [10 POINTS]\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, (5, 5)),\n",
    "            nn.Conv2d(8, 16, (3, 3)),\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, (6, 1)),\n",
    "        )\n",
    "\n",
    "        self.lstm = nn.Sequential(\n",
    "            nn.LSTM(32, 512, batch_first=True, num_layers=2, dropout=0.2)\n",
    "        )\n",
    "\n",
    "        self.hidden = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128, 5),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### FILL IN ### [5 POINTS]\n",
    "        x = self.conv1(x)\n",
    "        # x.shape = (batch_size//# trials, channels, height, width)\n",
    "        x = x.reshape(x.shape[0], x.shape[1], x.shape[3])\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.lstm(x)\n",
    "        x = x[0][:, -1, :]\n",
    "        x = self.hidden(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy subj_A=  0.2591240875912409\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 5.44 GiB (GPU 3; 10.92 GiB total capacity; 4.16 GiB already allocated; 549.44 MiB free; 9.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m targets \u001b[39m=\u001b[39m targets\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     24\u001b[0m \u001b[39m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m conv_lstm_predictions \u001b[39m=\u001b[39m conv_lstm(data)\n\u001b[1;32m     26\u001b[0m conv_lstm_loss \u001b[39m=\u001b[39m criterion(conv_lstm_predictions, targets)\n\u001b[1;32m     28\u001b[0m \u001b[39m# Backward pass\u001b[39;00m\n",
      "File \u001b[0;32m/net/home/store/home/cchen4/5F_EEG_DATA/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[4], line 42\u001b[0m, in \u001b[0;36mConv_LSTM.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     40\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mreshape(x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], x\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], x\u001b[39m.\u001b[39mshape[\u001b[39m3\u001b[39m])\n\u001b[1;32m     41\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[0;32m---> 42\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(x)\n\u001b[1;32m     43\u001b[0m x \u001b[39m=\u001b[39m x[\u001b[39m0\u001b[39m][:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :]\n\u001b[1;32m     44\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden(x)\n",
      "File \u001b[0;32m/net/home/store/home/cchen4/5F_EEG_DATA/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/net/home/store/home/cchen4/5F_EEG_DATA/.venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/net/home/store/home/cchen4/5F_EEG_DATA/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/net/home/store/home/cchen4/5F_EEG_DATA/.venv/lib/python3.10/site-packages/torch/nn/modules/rnn.py:812\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    811\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 812\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[1;32m    813\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[1;32m    814\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    815\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[1;32m    816\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 5.44 GiB (GPU 3; 10.92 GiB total capacity; 4.16 GiB already allocated; 549.44 MiB free; 9.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# run CNN+LSTM\n",
    "# train neural net\n",
    "\n",
    "torch.cuda.set_device(3)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "accuracies = []\n",
    "\n",
    "for subj, features, labels in fileList:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size= 0.3) # 70% training 30% test\n",
    "    conv_lstm = Conv_LSTM().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    conv_lstm_optimizer = torch.optim.Adam(conv_lstm.parameters(), lr=0.001)\n",
    "    # Train the neural network\n",
    "    for epoch in range(50):\n",
    "        # print(\"epoch = \",epoch)\n",
    "        conv_lstm.train()\n",
    "        data = X_train\n",
    "        targets = y_train\n",
    "        data = torch.tensor(data.reshape(int(data.shape[0]), 1, data.shape[1], data.shape[2]), dtype=torch.float32) # reshape # of trial, 1 channel, # of samples\n",
    "        data = data.to(device)\n",
    "        targets = torch.tensor(targets, dtype=torch.int64) # nn.functional.one_hot().type(torch.float32)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        conv_lstm_predictions = conv_lstm(data)\n",
    "        conv_lstm_loss = criterion(conv_lstm_predictions, targets)\n",
    "\n",
    "        # Backward pass\n",
    "        conv_lstm_optimizer.zero_grad()\n",
    "        conv_lstm_loss.backward()\n",
    "        conv_lstm_optimizer.step()\n",
    "\n",
    "    # Evaluate the neural network\n",
    "    conv_lstm.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        data = X_test\n",
    "        targets = y_test\n",
    "        data = torch.tensor(data.reshape(int(data.shape[0]), 1, data.shape[1], data.shape[2]), dtype=torch.float32) # reshape # of trial, 1 channel, # of samples\n",
    "        data = data.to(device)\n",
    "        targets = torch.tensor(targets, dtype=torch.int64) # nn.functional.one_hot().type(torch.float32)\n",
    "        targets = targets.to(device)\n",
    "        conv_lstm_predictions = conv_lstm(data)\n",
    "        _, predicted = torch.max(conv_lstm_predictions.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "    print(f\"test accuracy {subj}= \",correct/total)\n",
    "    accuracies.append(correct/total)\n",
    "\n",
    "print(f'avg accuracy = {np.mean(accuracies)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok finally consistent results :\n",
    "\n",
    "test accuracy subj_A=  0.3284671532846715\n",
    "test accuracy subj_B=  0.38286713286713286\n",
    "test accuracy subj_C=  0.38070175438596493\n",
    "test accuracy subj_E=  0.43391812865497076\n",
    "test accuracy subj_F=  0.26187717265353416\n",
    "test accuracy subj_G=  0.37478108581436076\n",
    "test accuracy subj_H=  0.3140794223826715\n",
    "test accuracy subj_I=  0.4010416666666667\n",
    "avg accuracy = 0.3597166895887467"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next steps!\n",
    "\n",
    "- try a minimal preprocessing approach and see if it improves anything (only bandpass filter and ica ???) the AAR might have messed things up last time, but not sure\n",
    "- figure out CNN LSTM ? transformers ? GRU\n",
    "- should i attempt any feature extraction ?\n",
    "- \n",
    "- maybe read raw ECoG data and apply this classifier on it to see?\n",
    "- see what happens if i combine ECoG and EEG data .. hm\n",
    "\n",
    "\n",
    "\n",
    "SUBJECT TRANSFER:\n",
    "- try randomizing samples\n",
    "- try a retuning 20% data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class gru_rnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(gru_rnn, self).__init__()\n",
    "        self.gru = nn.GRU(3800, 32, 3, dropout=0.2)\n",
    "        self.fc = nn.Linear(32, 5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.gru(x)[0]\n",
    "        # x = self.fc(self.relu(x[0]))\n",
    "        # x = self.hidden(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy subj_A=  0.22627737226277372\n",
      "test accuracy subj_B=  0.20279720279720279\n",
      "test accuracy subj_C=  0.18947368421052632\n",
      "test accuracy subj_E=  0.20701754385964913\n",
      "test accuracy subj_F=  0.20393974507531865\n",
      "test accuracy subj_G=  0.17513134851138354\n",
      "test accuracy subj_H=  0.21299638989169675\n",
      "test accuracy subj_I=  0.2378472222222222\n",
      "avg accuracy = 0.20693506360384664\n"
     ]
    }
   ],
   "source": [
    "# run gRU !\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "# train neural net\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "accuracies = []\n",
    "\n",
    "for subj, features, labels in fileList:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size= 0.3) # 70% training 30% test\n",
    "    neural_net = gru_rnn().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    neural_net_optimizer = torch.optim.Adam(neural_net.parameters(), lr=0.001)\n",
    "    # Train the neural network\n",
    "    for epoch in range(50):\n",
    "        # print(\"epoch = \",epoch)\n",
    "        neural_net.train()\n",
    "        data = X_train\n",
    "        targets = y_train\n",
    "        data = torch.tensor(data.reshape(int(data.shape[0]), data.shape[1]* data.shape[2]), dtype=torch.float32) # reshape # of trial, 1 channel, # of samples\n",
    "        data = data.to(device)\n",
    "        targets = torch.tensor(targets, dtype=torch.int64)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        neural_net_predictions = neural_net(data)\n",
    "        neural_net_loss = criterion(neural_net_predictions, targets)\n",
    "\n",
    "        # Backward pass\n",
    "        neural_net_optimizer.zero_grad()\n",
    "        neural_net_loss.backward()\n",
    "        neural_net_optimizer.step()\n",
    "\n",
    "    # Evaluate the neural network\n",
    "    neural_net.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        data = X_test\n",
    "        targets = y_test\n",
    "        data = torch.tensor(data.reshape(int(data.shape[0]), data.shape[1] * data.shape[2]), dtype=torch.float32) # reshape # of trial, 1 channel, # of samples\n",
    "        data = data.to(device)\n",
    "        targets = torch.tensor(targets, dtype=torch.int64)\n",
    "        targets = targets.to(device)\n",
    "        neural_net_predictions = neural_net(data)\n",
    "        _, predicted = torch.max(neural_net_predictions.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "    print(f\"test accuracy {subj}= \",correct/total)\n",
    "    accuracies.append(correct/total)\n",
    "\n",
    "print(f'avg accuracy = {np.mean(accuracies)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision tree regessor DX\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "for subj, features, labels in fileList:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size= 0.3) # 70% training 30% test\n",
    "\n",
    "    tree = DecisionTreeRegressor(max_depth=3, random_state=0)\n",
    "    tree.fit(data_train, target_train)\n",
    "\n",
    "    target_train_predicted = tree.predict(data_train)\n",
    "    target_test_predicted = tree.predict(data_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
