{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the raw data :')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# some hyperparameter type things :)\n",
    "sr = 200\n",
    "t = 200\n",
    "ch = 19\n",
    "affix = '_raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from .pkl files (\"raw\")\n",
    "raw_features = {}\n",
    "raw_labels = {}\n",
    "fileList = []\n",
    "\n",
    "for letter in ['A', 'B', 'C', 'E', 'F', 'G', 'H', 'I']: \n",
    "    raw_features[f'subj_{letter}'] = np.load(f'pickles/subj_{letter}_features{affix}.npy')\n",
    "    raw_labels[f'subj_{letter}'] = np.load(f'pickles/subj_{letter}_labels{affix}.npy').reshape(-1)\n",
    "    fileList.append((f'subj_{letter}', raw_features[f'subj_{letter}'], raw_labels[f'subj_{letter}']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConvNet_Finger\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class ConvNet_Finger(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet_Finger, self).__init__()\n",
    "        ### FILL IN ### [10 POINTS]\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, (7, 3)),\n",
    "            nn.ReLU(), \n",
    "            #nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(8, 16, (5, 3)),\n",
    "            nn.Conv2d(16, 32, (3, 3)),\n",
    "            nn.ReLU(),\n",
    "            #nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            #nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.hidden = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            # nn.Linear(121728, 256),\n",
    "            nn.Linear(43456, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4), # all features norefer\n",
    "            # nn.Linear(1408, 256), #pseudosampled featrues .\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128, 2),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### FILL IN ### [5 POINTS]\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        # x = self.conv3(x)\n",
    "        x = self.hidden(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final NeuralNet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        ### FILL IN ### [10 POINTS]\n",
    "\n",
    "        self.hidden = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            # nn.Linear(121728, 256),\n",
    "            nn.Linear(43456, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4), # all features norefer\n",
    "            # nn.Linear(1408, 256), #pseudosampled featrues .\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128, 5),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        nn.Sequential(\n",
    "            nn.Linear(5, 16),\n",
    "            nn.Linear(16, 32),\n",
    "            nn.Linear(32, 5)\n",
    "        )\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help :P\n",
    "\n",
    "def predict(y_train):\n",
    "    data = y_train\n",
    "    pred = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        data = data.to(device)\n",
    "        predictions = model(data)\n",
    "        _, predictions = predictions.max(1)\n",
    "    return predictions\n",
    "\n",
    "def evaluate(predictions, targets):\n",
    "    n_samples, n_correct = 0, 0\n",
    "    # print(targets.shape, predictions.shape)\n",
    "    # print(type(targets), targets.shape, type(predictions), len(predictions))\n",
    "    n_samples += targets.size(0)\n",
    "    n_correct += (predictions == targets).sum().item()\n",
    "    acc = n_correct / n_samples\n",
    "    print(f'accuracy = {acc}')\n",
    "    return acc\n",
    "\n",
    "def binary_confusion(y_pred, target):\n",
    "    # matrix represents [pred 0 targ 0, pred 0 targ 1] [pred 1 targ 0, pred 1 targ 1]\n",
    "    matrix = [[0, 0],[0, 0]]\n",
    "    for i in range(y_pred.shape[0]):\n",
    "        #zero stands for not thumb\n",
    "        if y_pred[i] == 0 and target[i] == 0:\n",
    "            matrix[0][0] += 1\n",
    "        elif y_pred[i] == 0 and target[i] == 1:\n",
    "            matrix[0][1] += 1\n",
    "        elif y_pred[i] == 1 and target[i] == 0:\n",
    "            matrix[1][0] += 1\n",
    "        elif y_pred[i] == 1 and target[i] == 1:\n",
    "            matrix[1][1] += 1\n",
    "    matrix = matrix/np.sum(matrix)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_73526/2044805763.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features = torch.transpose(torch.tensor(new_features, dtype=torch.float32), 0, 1).to(device).requires_grad_(True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained subj_A 4\n",
      "accuracy = 0.7846715328467153\n",
      "accuracy subj_A finger 0 = 0.7846715328467153 [[0.70620438 0.13686131]\n",
      " [0.07846715 0.07846715]])\n",
      "accuracy = 0.7864963503649635\n",
      "accuracy subj_A finger 1 = 0.7864963503649635 [[0.70985401 0.10218978]\n",
      " [0.11131387 0.07664234]])\n",
      "accuracy = 0.7664233576642335\n",
      "accuracy subj_A finger 2 = 0.7664233576642335 [[0.68978102 0.1350365 ]\n",
      " [0.09854015 0.07664234]])\n",
      "accuracy = 0.7737226277372263\n",
      "accuracy subj_A finger 3 = 0.7737226277372263 [[0.72080292 0.15875912]\n",
      " [0.06751825 0.05291971]])\n",
      "accuracy = 0.8193430656934306\n",
      "accuracy subj_A finger 4 = 0.8193430656934306 [[0.75547445 0.11861314]\n",
      " [0.0620438  0.06386861]])\n",
      "accuracy = 0.36496350364963503\n",
      "FINAL accuracy subj_A = 0.36496350364963503 ***************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_73526/2044805763.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features = torch.transpose(torch.tensor(new_features, dtype=torch.float32), 0, 1).to(device).requires_grad_(True)\n",
      "/tmp/ipykernel_73526/2044805763.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features = torch.transpose(torch.tensor(new_features, dtype=torch.float32), 0, 1).to(device).requires_grad_(True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained subj_B 4\n",
      "accuracy = 0.7753496503496503\n",
      "accuracy subj_B finger 0 = 0.7753496503496503 [[0.66083916 0.09527972]\n",
      " [0.12937063 0.11451049]])\n",
      "accuracy = 0.7884615384615384\n",
      "accuracy subj_B finger 1 = 0.7884615384615384 [[0.75699301 0.13986014]\n",
      " [0.07167832 0.03146853]])\n",
      "accuracy = 0.7229020979020979\n",
      "accuracy subj_B finger 2 = 0.7229020979020979 [[0.66433566 0.12937063]\n",
      " [0.14772727 0.05856643]])\n",
      "accuracy = 0.7709790209790209\n",
      "accuracy subj_B finger 3 = 0.7709790209790209 [[0.66870629 0.11363636]\n",
      " [0.11538462 0.10227273]])\n",
      "accuracy = 0.8155594405594405\n",
      "accuracy subj_B finger 4 = 0.8155594405594405 [[0.6993007  0.09877622]\n",
      " [0.08566434 0.11625874]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_73526/2044805763.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features = torch.transpose(torch.tensor(new_features, dtype=torch.float32), 0, 1).to(device).requires_grad_(True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.3916083916083916\n",
      "FINAL accuracy subj_B = 0.3916083916083916 ***************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_73526/2044805763.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features = torch.transpose(torch.tensor(new_features, dtype=torch.float32), 0, 1).to(device).requires_grad_(True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained subj_C 4\n",
      "accuracy = 0.8210526315789474\n",
      "accuracy subj_C finger 0 = 0.8210526315789474 [[0.72280702 0.11578947]\n",
      " [0.06315789 0.09824561]])\n",
      "accuracy = 0.7912280701754386\n",
      "accuracy subj_C finger 1 = 0.7912280701754386 [[0.70526316 0.08596491]\n",
      " [0.12280702 0.08596491]])\n",
      "accuracy = 0.8087719298245614\n",
      "accuracy subj_C finger 2 = 0.8087719298245614 [[0.73684211 0.11754386]\n",
      " [0.07368421 0.07192982]])\n",
      "accuracy = 0.8421052631578947\n",
      "accuracy subj_C finger 3 = 0.8421052631578947 [[0.71052632 0.05789474]\n",
      " [0.1        0.13157895]])\n",
      "accuracy = 0.843859649122807\n",
      "accuracy subj_C finger 4 = 0.843859649122807 [[0.68947368 0.08070175]\n",
      " [0.0754386  0.15438596]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_73526/2044805763.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features = torch.transpose(torch.tensor(new_features, dtype=torch.float32), 0, 1).to(device).requires_grad_(True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.5157894736842106\n",
      "FINAL accuracy subj_C = 0.5157894736842106 ***************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_73526/2044805763.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features = torch.transpose(torch.tensor(new_features, dtype=torch.float32), 0, 1).to(device).requires_grad_(True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained subj_E 4\n",
      "accuracy = 0.8339181286549707\n",
      "accuracy subj_E finger 0 = 0.8339181286549707 [[0.67134503 0.07602339]\n",
      " [0.09005848 0.1625731 ]])\n",
      "accuracy = 0.7871345029239766\n",
      "accuracy subj_E finger 1 = 0.7871345029239766 [[0.68654971 0.08187135]\n",
      " [0.13099415 0.1005848 ]])\n",
      "accuracy = 0.8175438596491228\n",
      "accuracy subj_E finger 2 = 0.8175438596491228 [[0.70994152 0.08888889]\n",
      " [0.09356725 0.10760234]])\n",
      "accuracy = 0.6654970760233918\n",
      "accuracy subj_E finger 3 = 0.6654970760233918 [[0.51578947 0.04795322]\n",
      " [0.28654971 0.1497076 ]])\n",
      "accuracy = 0.8444444444444444\n",
      "accuracy subj_E finger 4 = 0.8444444444444444 [[0.70526316 0.04561404]\n",
      " [0.10994152 0.13918129]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_73526/2044805763.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features = torch.transpose(torch.tensor(new_features, dtype=torch.float32), 0, 1).to(device).requires_grad_(True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.43625730994152045\n",
      "FINAL accuracy subj_E = 0.43625730994152045 ***************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_73526/2044805763.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features = torch.transpose(torch.tensor(new_features, dtype=torch.float32), 0, 1).to(device).requires_grad_(True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained subj_F 4\n",
      "accuracy = 0.7960602549246814\n",
      "accuracy subj_F finger 0 = 0.7960602549246814 [[0.79606025 0.20393975]\n",
      " [0.         0.        ]])\n",
      "accuracy = 0.816917728852839\n",
      "accuracy subj_F finger 1 = 0.816917728852839 [[0.81691773 0.18308227]\n",
      " [0.         0.        ]])\n",
      "accuracy = 0.7508690614136733\n",
      "accuracy subj_F finger 2 = 0.7508690614136733 [[0.71494786 0.18192352]\n",
      " [0.06720742 0.03592121]])\n",
      "accuracy = 0.8146002317497103\n",
      "accuracy subj_F finger 3 = 0.8146002317497103 [[0.81460023 0.18539977]\n",
      " [0.         0.        ]])\n",
      "accuracy = 0.7775202780996524\n",
      "accuracy subj_F finger 4 = 0.7775202780996524 [[0.73232908 0.16454229]\n",
      " [0.05793743 0.04519119]])\n",
      "accuracy = 0.2572421784472769\n",
      "FINAL accuracy subj_F = 0.2572421784472769 ***************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_73526/2044805763.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features = torch.transpose(torch.tensor(new_features, dtype=torch.float32), 0, 1).to(device).requires_grad_(True)\n",
      "/tmp/ipykernel_73526/2044805763.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features = torch.transpose(torch.tensor(new_features, dtype=torch.float32), 0, 1).to(device).requires_grad_(True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained subj_G 4\n",
      "accuracy = 0.8353765323992994\n",
      "accuracy subj_G finger 0 = 0.8353765323992994 [[0.67950963 0.06654991]\n",
      " [0.09807356 0.1558669 ]])\n",
      "accuracy = 0.8231173380035026\n",
      "accuracy subj_G finger 1 = 0.8231173380035026 [[0.82311734 0.17688266]\n",
      " [0.         0.        ]])\n",
      "accuracy = 0.7845884413309983\n",
      "accuracy subj_G finger 2 = 0.7845884413309983 [[0.72154116 0.16287215]\n",
      " [0.0525394  0.06304729]])\n",
      "accuracy = 0.7845884413309983\n",
      "accuracy subj_G finger 3 = 0.7845884413309983 [[0.71103327 0.13309982]\n",
      " [0.08231173 0.07355517]])\n",
      "accuracy = 0.8213660245183888\n",
      "accuracy subj_G finger 4 = 0.8213660245183888 [[0.72854641 0.07530648]\n",
      " [0.1033275  0.09281961]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_73526/2044805763.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features = torch.transpose(torch.tensor(new_features, dtype=torch.float32), 0, 1).to(device).requires_grad_(True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.3922942206654991\n",
      "FINAL accuracy subj_G = 0.3922942206654991 ***************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_73526/2044805763.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features = torch.transpose(torch.tensor(new_features, dtype=torch.float32), 0, 1).to(device).requires_grad_(True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained subj_H 4\n",
      "accuracy = 0.7003610108303249\n",
      "accuracy subj_H finger 0 = 0.7003610108303249 [[0.60649819 0.10830325]\n",
      " [0.19133574 0.09386282]])\n",
      "accuracy = 0.7436823104693141\n",
      "accuracy subj_H finger 1 = 0.7436823104693141 [[0.64981949 0.07942238]\n",
      " [0.17689531 0.09386282]])\n",
      "accuracy = 0.7220216606498195\n",
      "accuracy subj_H finger 2 = 0.7220216606498195 [[0.66064982 0.15162455]\n",
      " [0.12635379 0.06137184]])\n",
      "accuracy = 0.7436823104693141\n",
      "accuracy subj_H finger 3 = 0.7436823104693141 [[0.65703971 0.12635379]\n",
      " [0.1299639  0.0866426 ]])\n",
      "accuracy = 0.7545126353790613\n",
      "accuracy subj_H finger 4 = 0.7545126353790613 [[0.64259928 0.0866426 ]\n",
      " [0.15884477 0.11191336]])\n",
      "accuracy = 0.36101083032490977\n",
      "FINAL accuracy subj_H = 0.36101083032490977 ***************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_73526/2044805763.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features = torch.transpose(torch.tensor(new_features, dtype=torch.float32), 0, 1).to(device).requires_grad_(True)\n",
      "/tmp/ipykernel_73526/2044805763.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features = torch.transpose(torch.tensor(new_features, dtype=torch.float32), 0, 1).to(device).requires_grad_(True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained subj_I 4\n",
      "accuracy = 0.8489583333333334\n",
      "accuracy subj_I finger 0 = 0.8489583333333334 [[0.68923611 0.05381944]\n",
      " [0.09722222 0.15972222]])\n",
      "accuracy = 0.7326388888888888\n",
      "accuracy subj_I finger 1 = 0.7326388888888888 [[0.65798611 0.10763889]\n",
      " [0.15972222 0.07465278]])\n",
      "accuracy = 0.7673611111111112\n",
      "accuracy subj_I finger 2 = 0.7673611111111112 [[0.69791667 0.13541667]\n",
      " [0.09722222 0.06944444]])\n",
      "accuracy = 0.7274305555555556\n",
      "accuracy subj_I finger 3 = 0.7274305555555556 [[0.60243056 0.09548611]\n",
      " [0.17708333 0.125     ]])\n",
      "accuracy = 0.7864583333333334\n",
      "accuracy subj_I finger 4 = 0.7864583333333334 [[0.68402778 0.07638889]\n",
      " [0.13715278 0.10243056]])\n",
      "accuracy = 0.3923611111111111\n",
      "FINAL accuracy subj_I = 0.3923611111111111 ***************************************\n",
      "avg accuracy = 0.38894087742906935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_73526/2044805763.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features = torch.transpose(torch.tensor(new_features, dtype=torch.float32), 0, 1).to(device).requires_grad_(True)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "dropout = 0.2\n",
    "n_epochs = 30\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-6\n",
    "input_shape = (-1, 1, ch, t)\n",
    "\n",
    "torch.cuda.set_device(4)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "sm = SMOTE()\n",
    "\n",
    "# train neural net\n",
    "accuracies = []\n",
    "for subj, features, labels in fileList:\n",
    "    new_features = []\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size= 0.3) # 70% training 30% test\n",
    "    for finger in range(5):\n",
    "        y_train_ = np.where(y_train == finger, 1, 0)\n",
    "        y_test_ = np.where(y_test == finger, 1, 0)\n",
    "        X_res = X_train.reshape((X_train.shape[0], -1))\n",
    "        X_res, y_res = sm.fit_resample(X_res, y_train_)\n",
    "        X_res = X_res.reshape((X_res.shape[0], ch, -1))\n",
    "\n",
    "        model = ConvNet_Finger().to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        # Train the neural network\n",
    "\n",
    "        model.train()\n",
    "        data = X_res\n",
    "        targets = y_res\n",
    "        data = torch.tensor(data.reshape(int(data.shape[0]), 1, data.shape[1], data.shape[2]), dtype=torch.float32) # reshape # of trial, 1 channel, # of samples\n",
    "        data = data.to(device)\n",
    "        targets = torch.tensor(targets, dtype=torch.int64)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            # print(\"epoch = \",epoch)\n",
    "            model.train()\n",
    "\n",
    "            # Forward pass\n",
    "            predictions = model(data)\n",
    "            loss = criterion(predictions, targets)\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        torch.save(model.state_dict(), f'pickles/models/{subj}_finger_{finger}.pt')\n",
    "        \n",
    "        pred = predict(torch.as_tensor(X_train.reshape(input_shape), dtype=torch.float32).to(device))\n",
    "        new_features.append(pred*finger)\n",
    "    new_features = torch.stack(new_features)\n",
    "    features = torch.transpose(torch.tensor(new_features, dtype=torch.float32), 0, 1).to(device).requires_grad_(True)\n",
    "    \n",
    "    # final NeuralNet\n",
    "    model = NeuralNet().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Train the neural network\n",
    "    model.train()\n",
    "    data = features\n",
    "    targets = torch.tensor(y_train, dtype=torch.int64).to(device)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        # print(\"epoch = \",epoch)\n",
    "        model.train()\n",
    "\n",
    "        # Forward pass\n",
    "        predictions = model(data)\n",
    "        loss = criterion(predictions, targets)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    torch.save(model.state_dict(), f'pickles/models/{subj}_final.pt')\n",
    "\n",
    "    print(f'trained {subj} {finger}')\n",
    "    new_features = []\n",
    "\n",
    "    for finger in range(5):\n",
    "        model = ConvNet_Finger().to(device)\n",
    "        criterion = nn.CrossEntropyLoss\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        model.load_state_dict(torch.load(f'pickles/models/{subj}_finger_{finger}.pt'))\n",
    "\n",
    "        y_res = np.where(y_test == finger, 1, 0)\n",
    "        y_res = torch.tensor(y_res, dtype=torch.int64).to(device)\n",
    "        pred = predict(torch.tensor(X_test.reshape(input_shape), dtype=torch.float32).to(device))\n",
    "        print(f'accuracy {subj} finger {finger} = {evaluate(pred, y_res)} {binary_confusion(pred, y_res)})')\n",
    "        new_features.append(pred*finger)\n",
    "\n",
    "\n",
    "    new_features = torch.stack(new_features)\n",
    "    features = torch.transpose(torch.tensor(new_features, dtype=torch.float32), 0, 1).to(device).requires_grad_(True)\n",
    "    \n",
    "    model = NeuralNet().to(device)\n",
    "    model.load_state_dict(torch.load(f'pickles/models/{subj}_final.pt'))\n",
    "    acc = evaluate(predict(features), torch.tensor(y_test, dtype=torch.int64).to(device))\n",
    "    print(f'FINAL accuracy {subj} = {acc} ***************************************')\n",
    "    accuracies.append(acc)\n",
    "\n",
    "print(f'avg accuracy = {np.mean(accuracies)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained subj_A 4\n",
      "accuracy = 0.7828467153284672\n",
      "accuracy subj_A finger 0 = 0.7828467153284672 [[0.69890511 0.12043796]\n",
      " [0.09671533 0.08394161]])\n",
      "accuracy = 0.791970802919708\n",
      "accuracy subj_A finger 1 = 0.791970802919708 [[0.75       0.16240876]\n",
      " [0.04562044 0.0419708 ]])\n",
      "accuracy = 0.7846715328467153\n",
      "accuracy subj_A finger 2 = 0.7846715328467153 [[0.72262774 0.13138686]\n",
      " [0.08394161 0.0620438 ]])\n",
      "accuracy = 0.7737226277372263\n",
      "accuracy subj_A finger 3 = 0.7737226277372263 [[0.71350365 0.15145985]\n",
      " [0.07481752 0.06021898]])\n",
      "accuracy = 0.7956204379562044\n",
      "accuracy subj_A finger 4 = 0.7956204379562044 [[0.73722628 0.12773723]\n",
      " [0.07664234 0.05839416]])\n",
      "FINAL accuracy subj_A = 0.3467153284671533 ***************************************\n",
      "trained subj_B 4\n",
      "accuracy = 0.791958041958042\n",
      "accuracy subj_B finger 0 = 0.791958041958042 [[0.69318182 0.13636364]\n",
      " [0.07167832 0.09877622]])\n",
      "accuracy = 0.8085664335664335\n",
      "accuracy subj_B finger 1 = 0.8085664335664335 [[0.80856643 0.19143357]\n",
      " [0.         0.        ]])\n",
      "accuracy = 0.7867132867132867\n",
      "accuracy subj_B finger 2 = 0.7867132867132867 [[0.75524476 0.17045455]\n",
      " [0.04283217 0.03146853]])\n",
      "accuracy = 0.8059440559440559\n",
      "accuracy subj_B finger 3 = 0.8059440559440559 [[0.73863636 0.10926573]\n",
      " [0.08479021 0.06730769]])\n",
      "accuracy = 0.8312937062937062\n",
      "accuracy subj_B finger 4 = 0.8312937062937062 [[0.73426573 0.0979021 ]\n",
      " [0.0708042  0.09702797]])\n",
      "FINAL accuracy subj_B = 0.3793706293706294 ***************************************\n",
      "trained subj_C 4\n",
      "accuracy = 0.8210526315789474\n",
      "accuracy subj_C finger 0 = 0.8210526315789474 [[0.76315789 0.14385965]\n",
      " [0.03508772 0.05789474]])\n",
      "accuracy = 0.7666666666666667\n",
      "accuracy subj_C finger 1 = 0.7666666666666667 [[0.69122807 0.13684211]\n",
      " [0.09649123 0.0754386 ]])\n",
      "accuracy = 0.8\n",
      "accuracy subj_C finger 2 = 0.8 [[0.74385965 0.14736842]\n",
      " [0.05263158 0.05614035]])\n",
      "accuracy = 0.8350877192982457\n",
      "accuracy subj_C finger 3 = 0.8350877192982457 [[0.69649123 0.05087719]\n",
      " [0.11403509 0.13859649]])\n",
      "accuracy = 0.8614035087719298\n",
      "accuracy subj_C finger 4 = 0.8614035087719298 [[0.75438596 0.08596491]\n",
      " [0.05263158 0.10701754]])\n",
      "FINAL accuracy subj_C = 0.4614035087719298 ***************************************\n",
      "trained subj_E 4\n",
      "accuracy = 0.8280701754385965\n",
      "accuracy subj_E finger 0 = 0.8280701754385965 [[0.6877193  0.08421053]\n",
      " [0.0877193  0.14035088]])\n",
      "accuracy = 0.8549707602339182\n",
      "accuracy subj_E finger 1 = 0.8549707602339182 [[0.7625731  0.07836257]\n",
      " [0.06666667 0.09239766]])\n",
      "accuracy = 0.8128654970760234\n",
      "accuracy subj_E finger 2 = 0.8128654970760234 [[0.69122807 0.08070175]\n",
      " [0.10643275 0.12163743]])\n",
      "accuracy = 0.8\n",
      "accuracy subj_E finger 3 = 0.8 [[0.8 0.2]\n",
      " [0.  0. ]])\n",
      "accuracy = 0.8538011695906432\n",
      "accuracy subj_E finger 4 = 0.8538011695906432 [[0.72397661 0.07251462]\n",
      " [0.07368421 0.12982456]])\n",
      "FINAL accuracy subj_E = 0.4842105263157895 ***************************************\n",
      "trained subj_F 4\n",
      "accuracy = 0.7601390498261877\n",
      "accuracy subj_F finger 0 = 0.7601390498261877 [[0.69872538 0.14136732]\n",
      " [0.09849363 0.06141367]])\n",
      "accuracy = 0.813441483198146\n",
      "accuracy subj_F finger 1 = 0.813441483198146 [[0.81344148 0.18655852]\n",
      " [0.         0.        ]])\n",
      "accuracy = 0.7369640787949016\n",
      "accuracy subj_F finger 2 = 0.7369640787949016 [[0.70104287 0.18887601]\n",
      " [0.07415991 0.03592121]])\n",
      "accuracy = 0.761297798377752\n",
      "accuracy subj_F finger 3 = 0.761297798377752 [[0.73232908 0.17728853]\n",
      " [0.06141367 0.02896871]])\n",
      "accuracy = 0.7694090382387022\n",
      "accuracy subj_F finger 4 = 0.7694090382387022 [[0.73348783 0.14368482]\n",
      " [0.08690614 0.03592121]])\n",
      "FINAL accuracy subj_F = 0.25028968713789107 ***************************************\n",
      "trained subj_G 4\n",
      "accuracy = 0.8126094570928196\n",
      "accuracy subj_G finger 0 = 0.8126094570928196 [[0.66024518 0.05954466]\n",
      " [0.12784588 0.15236427]])\n",
      "accuracy = 0.7408056042031523\n",
      "accuracy subj_G finger 1 = 0.7408056042031523 [[0.66549912 0.09457093]\n",
      " [0.16462347 0.07530648]])\n",
      "accuracy = 0.7355516637478109\n",
      "accuracy subj_G finger 2 = 0.7355516637478109 [[0.64448336 0.1295972 ]\n",
      " [0.13485114 0.0910683 ]])\n",
      "accuracy = 0.6970227670753065\n",
      "accuracy subj_G finger 3 = 0.6970227670753065 [[0.57267951 0.0647986 ]\n",
      " [0.23817863 0.12434326]])\n",
      "accuracy = 0.7758318739054291\n",
      "accuracy subj_G finger 4 = 0.7758318739054291 [[0.66024518 0.09281961]\n",
      " [0.13134851 0.11558669]])\n",
      "FINAL accuracy subj_G = 0.3922942206654991 ***************************************\n",
      "trained subj_H 4\n",
      "accuracy = 0.7148014440433214\n",
      "accuracy subj_H finger 0 = 0.7148014440433214 [[0.61371841 0.12635379]\n",
      " [0.15884477 0.10108303]])\n",
      "accuracy = 0.7653429602888087\n",
      "accuracy subj_H finger 1 = 0.7653429602888087 [[0.68953069 0.09025271]\n",
      " [0.14440433 0.07581227]])\n",
      "accuracy = 0.6462093862815884\n",
      "accuracy subj_H finger 2 = 0.6462093862815884 [[0.60288809 0.1732852 ]\n",
      " [0.18050542 0.0433213 ]])\n",
      "accuracy = 0.6462093862815884\n",
      "accuracy subj_H finger 3 = 0.6462093862815884 [[0.53068592 0.06137184]\n",
      " [0.29241877 0.11552347]])\n",
      "accuracy = 0.7111913357400722\n",
      "accuracy subj_H finger 4 = 0.7111913357400722 [[0.58844765 0.09025271]\n",
      " [0.19855596 0.12274368]])\n",
      "FINAL accuracy subj_H = 0.3212996389891697 ***************************************\n",
      "trained subj_I 4\n",
      "accuracy = 0.8524305555555556\n",
      "accuracy subj_I finger 0 = 0.8524305555555556 [[0.72743056 0.10416667]\n",
      " [0.04340278 0.125     ]])\n",
      "accuracy = 0.6979166666666666\n",
      "accuracy subj_I finger 1 = 0.6979166666666666 [[0.60243056 0.08333333]\n",
      " [0.21875    0.09548611]])\n",
      "accuracy = 0.7743055555555556\n",
      "accuracy subj_I finger 2 = 0.7743055555555556 [[0.69965278 0.12847222]\n",
      " [0.09722222 0.07465278]])\n",
      "accuracy = 0.6840277777777778\n",
      "accuracy subj_I finger 3 = 0.6840277777777778 [[0.56944444 0.07465278]\n",
      " [0.24131944 0.11458333]])\n",
      "accuracy = 0.8420138888888888\n",
      "accuracy subj_I finger 4 = 0.8420138888888888 [[0.70659722 0.06423611]\n",
      " [0.09375    0.13541667]])\n",
      "FINAL accuracy subj_I = 0.3854166666666667 ***************************************\n",
      "avg accuracy = 0.3776250257980911\n"
     ]
    }
   ],
   "source": [
    "# ensemble w/ cnn + svm :eyes:\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "dropout = 0.2\n",
    "n_epochs = 30\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-6\n",
    "input_shape = (-1, 1, ch, t)\n",
    "\n",
    "torch.cuda.set_device(4)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "sm = SMOTE()\n",
    "\n",
    "# train neural net\n",
    "accuracies = []\n",
    "for subj, features, labels in fileList:\n",
    "    new_features = []\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size= 0.3) # 70% training 30% test\n",
    "    for finger in range(5):\n",
    "        y_train_ = np.where(y_train == finger, 1, 0)\n",
    "        y_test_ = np.where(y_test == finger, 1, 0)\n",
    "        X_res = X_train.reshape((X_train.shape[0], -1))\n",
    "        X_res, y_res = sm.fit_resample(X_res, y_train_)\n",
    "        X_res = X_res.reshape((X_res.shape[0], ch, -1))\n",
    "\n",
    "        model = ConvNet_Finger().to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        # Train the neural network\n",
    "\n",
    "        model.train()\n",
    "        data = X_res\n",
    "        targets = y_res\n",
    "        data = torch.tensor(data.reshape(int(data.shape[0]), 1, data.shape[1], data.shape[2]), dtype=torch.float32) # reshape # of trial, 1 channel, # of samples\n",
    "        data = data.to(device)\n",
    "        targets = torch.tensor(targets, dtype=torch.int64)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            # print(\"epoch = \",epoch)\n",
    "            model.train()\n",
    "\n",
    "            # Forward pass\n",
    "            predictions = model(data)\n",
    "            loss = criterion(predictions, targets)\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        torch.save(model.state_dict(), f'pickles/models/{subj}_finger_{finger}.pt')\n",
    "        \n",
    "        pred = predict(torch.as_tensor(X_train.reshape(input_shape), dtype=torch.float32).to(device))\n",
    "        new_features.append(pred.to('cpu')*finger)\n",
    "    features = np.array(new_features).transpose()\n",
    "\n",
    "    # final NeuralNet\n",
    "    classifier = svm.SVC(kernel='rbf')\n",
    "    classifier.fit(features, y_train)\n",
    "\n",
    "    print(f'trained {subj} {finger}')\n",
    "    new_features = []\n",
    "\n",
    "    for finger in range(5):\n",
    "        model = ConvNet_Finger().to(device)\n",
    "        criterion = nn.CrossEntropyLoss\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        model.load_state_dict(torch.load(f'pickles/models/{subj}_finger_{finger}.pt'))\n",
    "\n",
    "        y_res = np.where(y_test == finger, 1, 0)\n",
    "        y_res = torch.tensor(y_res, dtype=torch.int64).to(device)\n",
    "        pred = predict(torch.tensor(X_test.reshape(input_shape), dtype=torch.float32).to(device))\n",
    "        print(f'accuracy {subj} finger {finger} = {evaluate(pred, y_res)} {binary_confusion(pred, y_res)})')\n",
    "        new_features.append(pred.to('cpu')*finger)\n",
    "\n",
    "    features = np.array(new_features).transpose()\n",
    "\n",
    "    pred = classifier.predict(features)\n",
    "    acc = metrics.accuracy_score(y_test, pred)\n",
    "    print(f'FINAL accuracy {subj} = {acc} ***************************************')\n",
    "    accuracies.append(acc)\n",
    "\n",
    "print(f'avg accuracy = {np.mean(accuracies)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
