{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the raw data :')\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import re\n",
    "import random\n",
    "\n",
    "# some hyperparameter type things :)\n",
    "sr = 200\n",
    "t = 200\n",
    "ch = 19\n",
    "affix = '_raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from .pkl files (\"raw\")\n",
    "raw_features = {}\n",
    "raw_labels = {}\n",
    "fileList = []\n",
    "\n",
    "for letter in ['A', 'B', 'C', 'E', 'F', 'G', 'H', 'I']: \n",
    "    raw_features[f'subj_{letter}'] = np.load(f'pickles/subj_{letter}_features{affix}.npy')\n",
    "    raw_labels[f'subj_{letter}'] = np.load(f'pickles/subj_{letter}_labels{affix}.npy').reshape(-1)\n",
    "    fileList.append((f'subj_{letter}', raw_features[f'subj_{letter}'], raw_labels[f'subj_{letter}']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONt DO: relabel and resample ?\n",
    "\n",
    "fileList_thumb = []\n",
    "fileList_index = []\n",
    "fileList_middle = []\n",
    "fileList_ring = []\n",
    "fileList_pinky = []\n",
    "\n",
    "newFileList = []\n",
    "\n",
    "for idx, (subj, features, labels) in enumerate(fileList):\n",
    "    og_labels = labels\n",
    "    new_labels = []\n",
    "\n",
    "    new_labels.append(np.where(labels == 0, 1, 0)) # thumb\n",
    "    new_labels.append(np.where(labels == 1, 1, 0)) # index\n",
    "    new_labels.append(np.where(labels == 2, 1, 0)) # middle\n",
    "    new_labels.append(np.where(labels == 3, 1, 0)) # ring\n",
    "    new_labels.append(np.where(labels == 4, 1, 0)) # pinky\n",
    "\n",
    "    fileList[idx] = (subj, features, new_labels)\n",
    "    \n",
    "    # print('resampled dataset shape', Counter(y_res))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConvNet_Finger\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class ConvNet_Finger(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet_Finger, self).__init__()\n",
    "        ### FILL IN ### [10 POINTS]\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, (7, 3)),\n",
    "            nn.ReLU(), \n",
    "            #nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(8, 16, (5, 3)),\n",
    "            nn.Conv2d(16, 32, (3, 3)),\n",
    "            nn.ReLU(),\n",
    "            #nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            #nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.hidden = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            # nn.Linear(121728, 256),\n",
    "            nn.Linear(43456, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4), # all features norefer\n",
    "            # nn.Linear(1408, 256), #pseudosampled featrues .\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128, 2),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### FILL IN ### [5 POINTS]\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        # x = self.conv3(x)\n",
    "        x = self.hidden(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConvNet_2D\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class ConvNet_2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet_2D, self).__init__()\n",
    "        ### FILL IN ### [10 POINTS]\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, (7, 3)),\n",
    "            nn.ReLU(), \n",
    "            #nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(8, 16, (5, 3)),\n",
    "            nn.Conv2d(16, 32, (3, 3)),\n",
    "            nn.ReLU(),\n",
    "            #nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            #nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.hidden = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            # nn.Linear(121728, 256),\n",
    "            nn.Linear(43456, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4), # all features norefer\n",
    "            # nn.Linear(1408, 256), #pseudosampled featrues .\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128, 5),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### FILL IN ### [5 POINTS]\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        # x = self.conv3(x)\n",
    "        x = self.hidden(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final NeuralNet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        ### FILL IN ### [10 POINTS]\n",
    "\n",
    "        self.hidden = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            # nn.Linear(121728, 256),\n",
    "            nn.Linear(43456, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4), # all features norefer\n",
    "            # nn.Linear(1408, 256), #pseudosampled featrues .\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128, 5),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        nn.Sequential(\n",
    "            nn.Linear(5, 16),\n",
    "            nn.Linear(16, 32),\n",
    "            nn.Linear(32, 5)\n",
    "        )\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def train(train_loader, n_epochs):\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "            # print('batch = ', batch_idx)\n",
    "            data = data.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            model.train()\n",
    "            predictions = model(data)\n",
    "            loss = criterion(predictions, targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict(y_train):\n",
    "    data = y_train\n",
    "    pred = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        data = data.to(device)\n",
    "        predictions = model(data)\n",
    "        _, predictions = predictions.max(1)\n",
    "    return predictions\n",
    "\n",
    "def evaluate(predictions, targets):\n",
    "    n_samples, n_correct = 0, 0\n",
    "    # print(targets.shape, predictions.shape)\n",
    "    # print(type(targets), targets.shape, type(predictions), len(predictions))\n",
    "    n_samples += targets.size(0)\n",
    "    n_correct += (predictions == targets).sum().item()\n",
    "    acc = n_correct / n_samples\n",
    "    print(f'accuracy = {acc}')\n",
    "    return acc\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        super(Dataset, self).__init__()\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.shape = features.shape, labels.shape\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i tried to change the code but i dont think this is correct :D\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# train neural net\n",
    "torch.cuda.set_device(3)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "sm = SMOTE()\n",
    "\n",
    "batch_size = 32\n",
    "dropout = 0.2\n",
    "n_epochs = 50\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-6\n",
    "\n",
    "accuracies = []\n",
    "for subj, features, labels in fileList:\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, finger, test_size= 0.5) # 70% training 30% test\n",
    "        \n",
    "    test_dataset = EEGDataset(X_test, y_test)\n",
    "    finger_predictions = []\n",
    "    for finger in range(5):\n",
    "        # alter and resample data\n",
    "        y_train = np.where(labels == finger, 1, 0)\n",
    "        X_train = X_train.reshape((X_train.shape[0], -1))\n",
    "        X_res, y_res = sm.fit_resample(X_train, y_train)\n",
    "        X_res = X_res.reshape((X_res.shape[0], ch, -1))\n",
    "\n",
    "        # for ConvNet_2D, the input is (batch, channels, height, width)\n",
    "        input_shape = (X_res.shape[0], 1, X_res.shape[1], X_res.shape[2])\n",
    "        # for transformer it's.... idk :p\n",
    "        features = torch.tensor(X_res.reshape(input_shape), dtype=torch.float32).to(device)\n",
    "        labels = torch.tensor(y_res, dtype=torch.int64).to(device)\n",
    "        train_dataset = EEGDataset(features, labels)\n",
    "        train_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        model = ConvNet_Finger().to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "\n",
    "        model = train(train_loader, n_epochs)\n",
    "        pred = predict(train_loader)\n",
    "\n",
    "        finger_predictions.append(pred)\n",
    "    finger_predictions = np.array(finger_predictions).T \n",
    "    print(finger_predictions.shape)\n",
    "    X_train, y_train = finger_predictions, labels\n",
    "    \n",
    "    model = ConvNet_2D().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    train_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    model = train(train_loader, n_epochs)\n",
    "    pred = predict(train_loader)\n",
    "    acc = evaluate(pred, y_train)\n",
    "    print('acc on test = ', acc)\n",
    "\n",
    "    test_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
    "    predict\n",
    "    print(f'avg accuracy = {np.mean(accuracies)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m targets \u001b[39m=\u001b[39m y_res\n\u001b[1;32m     32\u001b[0m data \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(data\u001b[39m.\u001b[39mreshape(\u001b[39mint\u001b[39m(data\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]), \u001b[39m1\u001b[39m, data\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], data\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m]), dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32) \u001b[39m# reshape # of trial, 1 channel, # of samples\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m     34\u001b[0m targets \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(targets, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mint64)\n\u001b[1;32m     35\u001b[0m targets \u001b[39m=\u001b[39m targets\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# original 2 class classifier code :D\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# train neural net\n",
    "torch.cuda.set_device(3)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# device = 'cpu'\n",
    "sm = SMOTE()\n",
    "accuracies = []\n",
    "for subj, features, labels in fileList:\n",
    "    finger_predictions = []\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size= 0.3) # 70% training 30% test  \n",
    "    for finger in range(5):\n",
    "        y_train_ = np.where(y_train == finger, 1, 0)\n",
    "        y_test_ = np.where(y_test == finger, 1, 0)\n",
    "        X_res = X_train.reshape((X_train.shape[0], -1))\n",
    "        X_res, y_res = sm.fit_resample(X_res, y_train_)\n",
    "        X_res = X_res.reshape((X_res.shape[0], ch, -1))\n",
    "        conv_net = ConvNet_Finger().to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        conv_net_optimizer = torch.optim.Adam(conv_net.parameters(), lr=0.001)\n",
    "        # Train the neural network\n",
    "        for epoch in range(50):\n",
    "            # print(\"epoch = \",epoch)\n",
    "            conv_net.train()\n",
    "            data = X_res\n",
    "            targets = y_res\n",
    "            data = torch.tensor(data.reshape(int(data.shape[0]), 1, data.shape[1], data.shape[2]), dtype=torch.float32) # reshape # of trial, 1 channel, # of samples\n",
    "            data = data.to(device)\n",
    "            targets = torch.tensor(targets, dtype=torch.int64)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            conv_net_predictions = conv_net(data)\n",
    "            conv_net_loss = criterion(conv_net_predictions, targets)\n",
    "\n",
    "            # Backward pass\n",
    "            conv_net_optimizer.zero_grad()\n",
    "            conv_net_loss.backward()\n",
    "            conv_net_optimizer.step()\n",
    "\n",
    "        # Evaluate the neural network\n",
    "        conv_net.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            data = X_test\n",
    "            targets = y_test_\n",
    "            data = torch.tensor(data.reshape(int(data.shape[0]), 1, data.shape[1], data.shape[2]), dtype=torch.float32) # reshape # of trial, 1 channel, # of samples\n",
    "            data = data.to(device)\n",
    "            targets = torch.tensor(targets, dtype=torch.int64)\n",
    "            targets = targets.to(device)\n",
    "            conv_net_predictions = conv_net(data)\n",
    "            _, predicted = torch.max(conv_net_predictions.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            print(binary_confusion(predicted, targets))\n",
    "\n",
    "        print(f\"test accuracy {subj} = \",correct/total)\n",
    "        accuracies.append(correct/total)\n",
    "\n",
    "    print(f'avg accuracy = {np.mean(accuracies)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.7700729927007299\n",
      "test accuracy subj_A 0 =  0.7700729927007299\n",
      "confusion matrix: [[0.77007299 0.22992701]\n",
      " [0.         0.        ]]\n",
      "accuracy = 0.7609489051094891\n",
      "test accuracy subj_A 1 =  0.7609489051094891\n",
      "confusion matrix: [[0.74817518 0.19525547]\n",
      " [0.04379562 0.01277372]]\n",
      "accuracy = 0.7974452554744526\n",
      "test accuracy subj_A 2 =  0.7974452554744526\n",
      "confusion matrix: [[0.79744526 0.20255474]\n",
      " [0.         0.        ]]\n",
      "accuracy = 0.8193430656934306\n",
      "test accuracy subj_A 3 =  0.8193430656934306\n",
      "confusion matrix: [[0.81934307 0.18065693]\n",
      " [0.         0.        ]]\n",
      "accuracy = 0.8211678832116789\n",
      "test accuracy subj_A 4 =  0.8211678832116789\n",
      "confusion matrix: [[0.82116788 0.17883212]\n",
      " [0.         0.        ]]\n",
      "torch.Size([548, 1, 19, 200]) torch.Size([548])\n",
      "accuracy = 0.21715328467153286\n",
      "FINAL accuracy subj_A = 0.21715328467153286 *********************\n",
      "accuracy = 0.7867132867132867\n",
      "test accuracy subj_B 0 =  0.7867132867132867\n",
      "confusion matrix: [[0.71416084 0.15297203]\n",
      " [0.06031469 0.07255245]]\n",
      "accuracy = 0.6844405594405595\n",
      "test accuracy subj_B 1 =  0.6844405594405595\n",
      "confusion matrix: [[0.62237762 0.13374126]\n",
      " [0.18181818 0.06206294]]\n",
      "accuracy = 0.798951048951049\n",
      "test accuracy subj_B 2 =  0.798951048951049\n",
      "confusion matrix: [[0.79895105 0.20104895]\n",
      " [0.         0.        ]]\n",
      "accuracy = 0.8146853146853147\n",
      "test accuracy subj_B 3 =  0.8146853146853147\n",
      "confusion matrix: [[0.81468531 0.18531469]\n",
      " [0.         0.        ]]\n",
      "accuracy = 0.8076923076923077\n",
      "test accuracy subj_B 4 =  0.8076923076923077\n",
      "confusion matrix: [[0.80769231 0.19230769]\n",
      " [0.         0.        ]]\n",
      "torch.Size([1144, 1, 19, 200]) torch.Size([1144])\n",
      "accuracy = 0.23339160839160839\n",
      "FINAL accuracy subj_B = 0.23339160839160839 *********************\n",
      "accuracy = 0.7859649122807018\n",
      "test accuracy subj_C 0 =  0.7859649122807018\n",
      "confusion matrix: [[0.78596491 0.21403509]\n",
      " [0.         0.        ]]\n",
      "accuracy = 0.8035087719298246\n",
      "test accuracy subj_C 1 =  0.8035087719298246\n",
      "confusion matrix: [[0.80350877 0.19649123]\n",
      " [0.         0.        ]]\n",
      "accuracy = 0.7842105263157895\n",
      "test accuracy subj_C 2 =  0.7842105263157895\n",
      "confusion matrix: [[0.78421053 0.21578947]\n",
      " [0.         0.        ]]\n",
      "accuracy = 0.8087719298245614\n",
      "test accuracy subj_C 3 =  0.8087719298245614\n",
      "confusion matrix: [[0.80877193 0.19122807]\n",
      " [0.         0.        ]]\n",
      "accuracy = 0.8175438596491228\n",
      "test accuracy subj_C 4 =  0.8175438596491228\n",
      "confusion matrix: [[0.81754386 0.18245614]\n",
      " [0.         0.        ]]\n",
      "torch.Size([570, 1, 19, 200]) torch.Size([570])\n",
      "accuracy = 0.21403508771929824\n",
      "FINAL accuracy subj_C = 0.21403508771929824 *********************\n",
      "accuracy = 0.7929824561403509\n",
      "test accuracy subj_E 0 =  0.7929824561403509\n",
      "confusion matrix: [[0.79298246 0.20701754]\n",
      " [0.         0.        ]]\n",
      "accuracy = 0.8269005847953217\n",
      "test accuracy subj_E 1 =  0.8269005847953217\n",
      "confusion matrix: [[0.82690058 0.17309942]\n",
      " [0.         0.        ]]\n",
      "accuracy = 0.7964912280701755\n",
      "test accuracy subj_E 2 =  0.7964912280701755\n",
      "confusion matrix: [[0.79649123 0.20350877]\n",
      " [0.         0.        ]]\n",
      "accuracy = 0.7847953216374269\n",
      "test accuracy subj_E 3 =  0.7847953216374269\n",
      "confusion matrix: [[0.78479532 0.21520468]\n",
      " [0.         0.        ]]\n",
      "accuracy = 0.7988304093567251\n",
      "test accuracy subj_E 4 =  0.7988304093567251\n",
      "confusion matrix: [[0.79883041 0.20116959]\n",
      " [0.         0.        ]]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "PytorchStreamReader failed reading zip archive: failed finding central directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 100\u001b[0m\n\u001b[1;32m     98\u001b[0m y_res \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(y_test \u001b[39m==\u001b[39m finger, \u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[1;32m     99\u001b[0m y_res \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(y_res, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mint64)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m--> 100\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39;49mload(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpickles/models/\u001b[39;49m\u001b[39m{\u001b[39;49;00msubj\u001b[39m}\u001b[39;49;00m\u001b[39m_finger_\u001b[39;49m\u001b[39m{\u001b[39;49;00mfinger\u001b[39m}\u001b[39;49;00m\u001b[39m.pt\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m    101\u001b[0m pred \u001b[39m=\u001b[39m predict(torch\u001b[39m.\u001b[39mtensor(X_test\u001b[39m.\u001b[39mreshape(input_shape), dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\u001b[39m.\u001b[39mto(device))\n\u001b[1;32m    102\u001b[0m new_features\u001b[39m.\u001b[39mappend(pred\u001b[39m*\u001b[39mfinger)\n",
      "File \u001b[0;32m/net/home/store/home/cchen4/5F_EEG_DATA/.venv/lib/python3.10/site-packages/torch/serialization.py:797\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    793\u001b[0m     \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m     \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    795\u001b[0m     \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    796\u001b[0m     orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n\u001b[0;32m--> 797\u001b[0m     \u001b[39mwith\u001b[39;00m _open_zipfile_reader(opened_file) \u001b[39mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    798\u001b[0m         \u001b[39mif\u001b[39;00m _is_torchscript_zip(opened_zipfile):\n\u001b[1;32m    799\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtorch.load\u001b[39m\u001b[39m'\u001b[39m\u001b[39m received a zip file that looks like a TorchScript archive\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    800\u001b[0m                           \u001b[39m\"\u001b[39m\u001b[39m dispatching to \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtorch.jit.load\u001b[39m\u001b[39m'\u001b[39m\u001b[39m (call \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtorch.jit.load\u001b[39m\u001b[39m'\u001b[39m\u001b[39m directly to\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    801\u001b[0m                           \u001b[39m\"\u001b[39m\u001b[39m silence this warning)\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mUserWarning\u001b[39;00m)\n",
      "File \u001b[0;32m/net/home/store/home/cchen4/5F_EEG_DATA/.venv/lib/python3.10/site-packages/torch/serialization.py:283\u001b[0m, in \u001b[0;36m_open_zipfile_reader.__init__\u001b[0;34m(self, name_or_buffer)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name_or_buffer) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 283\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49mPyTorchFileReader(name_or_buffer))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: PytorchStreamReader failed reading zip archive: failed finding central directory"
     ]
    }
   ],
   "source": [
    "# wip condensed 2 class code that saves the models !\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "# train neural net\n",
    "torch.cuda.set_device(3)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "sm = SMOTE()\n",
    "\n",
    "batch_size = 32\n",
    "dropout = 0.2\n",
    "n_epochs = 50\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-6\n",
    "input_shape = (-1, 1, ch, t)\n",
    "\n",
    "accuracies = []\n",
    "for subj, features, labels in fileList:\n",
    "\n",
    "    #train test split first so WE NEVER EVER LOOK AT TEST BEFORE THE END !!!!\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size= 0.3) # 70% training 30% test\n",
    "    X_test = torch.tensor(X_test.reshape(input_shape), dtype=torch.float32).to(device)\n",
    "    test_dataset = EEGDataset(X_test, y_test)\n",
    "    \n",
    "    new_features = []\n",
    "    # train models for each finger\n",
    "    for finger in range(5):\n",
    "\n",
    "        # alter and resample the data\n",
    "        y_res = np.where(y_train == finger, 1, 0)\n",
    "        X_res = X_train.reshape((X_train.shape[0], -1))\n",
    "        X_res, y_res = sm.fit_resample(X_res, y_res)\n",
    "        X_res = X_res.reshape((X_res.shape[0], ch, -1))\n",
    "        # X_res = X_train\n",
    "\n",
    "        # reshape the data for the model type :P.\n",
    "        # for conv net its (batch, channel, height, width)\n",
    "\n",
    "        X_res = torch.tensor(X_res.reshape(input_shape), dtype=torch.float32).to(device)\n",
    "        y_res = torch.tensor(y_res, dtype=torch.int64).to(device)\n",
    "        res_dataset = EEGDataset(X_res, y_res)\n",
    "        res_loader = DataLoader(dataset=res_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        # params\n",
    "        model = ConvNet_Finger().to(device)\n",
    "        normedWeights = [1 - (x/100) for x in [80, 20]]\n",
    "        normedWeights = torch.FloatTensor(normedWeights).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        \n",
    "        # train and save neural net\n",
    "        model = train(res_loader, n_epochs)\n",
    "        torch.save(model.state_dict(), f'pickles/models/{subj}_finger_{finger}.pt')\n",
    "        # model.load_state_dict(torch.load(f'pickles/models/{subj}_finger_{finger}.pt'))\n",
    "        # lets peek at the test set. for each class so we gotta modify it...\n",
    "        two_y = np.where(y_test == finger, 1, 0)\n",
    "        two_y = torch.tensor(two_y, dtype=torch.int64).to(device)\n",
    "        pred = predict(torch.tensor(X_test.reshape(input_shape), dtype=torch.float32).to(device))\n",
    "        acc = evaluate(pred, two_y)\n",
    "        print(f\"test accuracy {subj} {finger} = \", acc)\n",
    "        print(f'confusion matrix: {binary_confusion(pred, two_y)}')\n",
    "\n",
    "        # now that model is built, lets use it to classify the og, unbalanced train set:\n",
    "        # train_dataset = EEGDataset(X_train, y_train)\n",
    "        # train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        pred = predict(torch.as_tensor(X_train.reshape(input_shape), dtype=torch.float32).to(device))\n",
    "        new_features.append(pred*finger)\n",
    "\n",
    "    # use these predictions as input for the final classifer training\n",
    "    new_features = torch.stack(new_features)\n",
    "    features = torch.transpose(torch.tensor(new_features, dtype=torch.float32), 0, 1).to(device).requires_grad_(True)\n",
    "    train_dataset = EEGDataset(features, y_train)\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    model = NeuralNet().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # train final classifier\n",
    "    model.train()\n",
    "    model = train(train_loader, n_epochs)\n",
    "    torch.save(model.state_dict(), f'pickles/models/{subj}_final.pt')\n",
    "    # model.load_state_dict(torch.load(f'pickles/models/{subj}_final.pt'))\n",
    "\n",
    "    # get features for final classifier\n",
    "    new_features = []\n",
    "    for finger in range(5):\n",
    "        # alter data\n",
    "        model = ConvNet_Finger().to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        \n",
    "        y_res = np.where(y_test == finger, 1, 0)\n",
    "        y_res = torch.tensor(y_res, dtype=torch.int64).to(device)\n",
    "        model.load_state_dict(torch.load(f'pickles/models/{subj}_finger_{finger}.pt'))\n",
    "        pred = predict(torch.tensor(X_test.reshape(input_shape), dtype=torch.float32).to(device))\n",
    "        new_features.append(pred*finger)\n",
    "    # test final classifier\n",
    "    y_test = torch.tensor(y_test, dtype=torch.int64).to(device)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    new_features = torch.stack(new_features)\n",
    "    features = torch.transpose(torch.tensor(new_features), 0, 1).to(device)\n",
    "\n",
    "    model = NeuralNet().to(device)\n",
    "    model.load_state_dict(torch.load(f'pickles/models/{subj}_final.pt'))\n",
    "    print(X_test.shape, y_test.shape)\n",
    "    acc = evaluate(predict(features), y_test)\n",
    "    print(f'FINAL accuracy {subj} = {acc} *********************')\n",
    "    accuracies.append(acc)\n",
    "print(f'avg accuracy = {np.mean(accuracies)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m new_features \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtensor(new_features)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(new_features\u001b[39m.\u001b[39mshape)\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer tensors of a single element can be converted to an index"
     ]
    }
   ],
   "source": [
    "new_features = torch.tensor(new_features).to(device)\n",
    "print(new_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_confusion(y_pred, target):\n",
    "    # matrix represents [pred 0 targ 0, pred 0 targ 1] [pred 1 targ 0, pred 1 targ 1]\n",
    "    matrix = [[0, 0],[0, 0]]\n",
    "    for i in range(y_pred.shape[0]):\n",
    "        #zero stands for not thumb\n",
    "        if y_pred[i] == 0 and target[i] == 0:\n",
    "            matrix[0][0] += 1\n",
    "        elif y_pred[i] == 0 and target[i] == 1:\n",
    "            matrix[0][1] += 1\n",
    "        elif y_pred[i] == 1 and target[i] == 0:\n",
    "            matrix[1][0] += 1\n",
    "        elif y_pred[i] == 1 and target[i] == 1:\n",
    "            matrix[1][1] += 1\n",
    "    matrix = matrix/np.sum(matrix)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[358, 55], [55, 385]]\n",
    "test accuracy subj_A =  0.8710433763188745\n",
    "[[767, 68], [140, 806]]\n",
    "test accuracy subj_B =  0.8832116788321168\n",
    "[[410, 35], [61, 411]]\n",
    "test accuracy subj_C =  0.8953107960741549\n",
    "[[608, 65], [65, 599]]\n",
    "test accuracy subj_E =  0.9027673896783844\n",
    "[[608, 41], [90, 613]]\n",
    "test accuracy subj_F =  0.9031065088757396\n",
    "[[347, 61], [57, 427]]\n",
    "test accuracy subj_G =  0.8677130044843049\n",
    "[[174, 34], [32, 192]]\n",
    "test accuracy subj_H =  0.8472222222222222\n",
    "[[398, 77], [63, 362]]\n",
    "test accuracy subj_I =  0.8444444444444444\n",
    "avg accuracy = 0.8768524276162802\n",
    "\n",
    "\n",
    "\n",
    "[[417, 33], [29, 417]]\n",
    "test accuracy subj_A =  0.9308035714285714\n",
    "[[817, 99], [102, 844]]\n",
    "test accuracy subj_B =  0.8920515574650913\n",
    "[[436, 48], [54, 379]]\n",
    "test accuracy subj_C =  0.8887677208287895\n",
    "[[658, 51], [65, 628]]\n",
    "test accuracy subj_E =  0.9172610556348074\n",
    "[[660, 52], [54, 647]]\n",
    "test accuracy subj_F =  0.9249823071479123\n",
    "[[402, 28], [74, 432]]\n",
    "test accuracy subj_G =  0.8910256410256411\n",
    "[[173, 31], [72, 177]]\n",
    "test accuracy subj_H =  0.7726269315673289\n",
    "[[371, 75], [90, 408]]\n",
    "test accuracy subj_I =  0.8252118644067796\n",
    "avg accuracy = 0.8785968794021977\n",
    "\n",
    "\n",
    "\n",
    "[[345, 45], [71, 409]]\n",
    "test accuracy subj_A =  0.8666666666666667\n",
    "[[810, 166], [95, 752]]\n",
    "test accuracy subj_B =  0.8568294020844761\n",
    "[[401, 50], [50, 405]]\n",
    "test accuracy subj_C =  0.8896247240618101\n",
    "[[615, 58], [86, 596]]\n",
    "test accuracy subj_E =  0.8937269372693727\n",
    "[[586, 82], [87, 613]]\n",
    "test accuracy subj_F =  0.8764619883040936\n",
    "[[405, 63], [53, 383]]\n",
    "test accuracy subj_G =  0.8716814159292036\n",
    "[[191, 41], [25, 185]]\n",
    "test accuracy subj_H =  0.8506787330316742\n",
    "[[396, 42], [57, 418]]\n",
    "test accuracy subj_I =  0.891566265060241\n",
    "avg accuracy = 0.8772827584517792\n",
    "\n",
    "\n",
    "\n",
    "[[371, 22], [80, 407]]\n",
    "test accuracy subj_A =  0.884090909090909\n",
    "[[829, 212], [80, 721]]\n",
    "test accuracy subj_B =  0.8414766558089034\n",
    "[[380, 34], [46, 452]]\n",
    "test accuracy subj_C =  0.9122807017543859\n",
    "[[604, 33], [75, 657]]\n",
    "test accuracy subj_E =  0.9211102994886778\n",
    "[[599, 77], [87, 618]]\n",
    "test accuracy subj_F =  0.8812454742939899\n",
    "[[389, 53], [55, 419]]\n",
    "test accuracy subj_G =  0.8820960698689956\n",
    "[[174, 49], [42, 178]]\n",
    "test accuracy subj_H =  0.7945823927765236\n",
    "[[331, 52], [117, 422]]\n",
    "test accuracy subj_I =  0.8167028199566161\n",
    "avg accuracy = 0.8746366101838032\n",
    "\n",
    "\n",
    "\n",
    "[[384, 39], [48, 414]]\n",
    "test accuracy subj_A =  0.9016949152542373\n",
    "[[855, 104], [102, 780]]\n",
    "test accuracy subj_B =  0.8881042911461162\n",
    "[[443, 34], [30, 401]]\n",
    "test accuracy subj_C =  0.9295154185022027\n",
    "[[634, 44], [58, 638]]\n",
    "test accuracy subj_E =  0.925764192139738\n",
    "[[590, 66], [78, 651]]\n",
    "test accuracy subj_F =  0.896028880866426\n",
    "[[385, 92], [81, 359]]\n",
    "test accuracy subj_G =  0.8113413304252999\n",
    "[[210, 25], [31, 178]]\n",
    "test accuracy subj_H =  0.8738738738738738\n",
    "[[393, 48], [67, 416]]\n",
    "test accuracy subj_I =  0.8755411255411255\n",
    "avg accuracy = 0.877255888840768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
